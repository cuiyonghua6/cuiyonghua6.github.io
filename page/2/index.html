<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">






<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css">


  <meta name="keywords" content="Hexo, NexT">








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0">






<meta name="description" content="No pain, no gain.">
<meta property="og:type" content="website">
<meta property="og:title" content="崔永华的个人网站">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="崔永华的个人网站">
<meta property="og:description" content="No pain, no gain.">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="崔永华的个人网站">
<meta name="twitter:description" content="No pain, no gain.">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/">





  <title> 崔永华的个人网站 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">崔永华的个人网站</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description"></h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/python/spider/scrapy/20200705_ middleware/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="崔永华（Andy）">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="崔永华的个人网站">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/07/python/spider/scrapy/20200705_ middleware/" itemprop="url">
                  scrapy源码5：middleware的源码分析
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-07-05T10:35:00+08:00">
                2020-07-05
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/爬虫/" itemprop="url" rel="index">
                    <span itemprop="name">爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          
            <p>这个文件是中间件的基类了。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这几个都是引用默认字典， 日志， 打印的，没啥问题。 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> NotConfigured</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.misc <span class="keyword">import</span> load_object</span><br><span class="line"><span class="comment"># 导入了notconfigure没有配置的异常， 导入了load_object去完成字符串到对应类对象的方法。前面已经提到了。 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy.utils.defer <span class="keyword">import</span> process_parallel, process_chain, process_chain_both</span><br><span class="line"><span class="comment"># 这几个方法都在defer里面。 我们定位过去看看。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_parallel</span><span class="params">(callbacks, input, *a, **kw)</span>:</span></span><br><span class="line">    <span class="string">"""Return a Deferred with the output of all successful calls to the given</span></span><br><span class="line"><span class="string">    callbacks</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    dfds = [defer.succeed(input).addCallback(x, *a, **kw) <span class="keyword">for</span> x <span class="keyword">in</span> callbacks]</span><br><span class="line">    d = defer.DeferredList(dfds, fireOnOneErrback=<span class="number">1</span>, consumeErrors=<span class="number">1</span>)</span><br><span class="line">    d.addCallbacks(<span class="keyword">lambda</span> r: [x[<span class="number">1</span>] <span class="keyword">for</span> x <span class="keyword">in</span> r], <span class="keyword">lambda</span> f: f.value.subFailure)</span><br><span class="line">    <span class="keyword">return</span> d</span><br><span class="line"><span class="comment"># 这个方法完成的功能就是返回一个带有所有成功输出的defrred，通过给定的callback方法。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 并行处理，得到dfds， 添加一个成功回调。 一个错误回调。 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_chain</span><span class="params">(callbacks, input, *a, **kw)</span>:</span></span><br><span class="line">    <span class="string">"""Return a Deferred built by chaining the given callbacks"""</span></span><br><span class="line">    d = defer.Deferred()</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> callbacks:</span><br><span class="line">        d.addCallback(x, *a, **kw)</span><br><span class="line">    d.callback(input)</span><br><span class="line">    <span class="keyword">return</span> d  <span class="comment"># 这个方法将所有回调方法添加给deferred对象上， 然后给input</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_chain_both</span><span class="params">(callbacks, errbacks, input, *a, **kw)</span>:</span></span><br><span class="line">    <span class="string">"""Return a Deferred built by chaining the given callbacks and errbacks"""</span></span><br><span class="line">    d = defer.Deferred()</span><br><span class="line">    <span class="keyword">for</span> cb, eb <span class="keyword">in</span> zip(callbacks, errbacks):</span><br><span class="line">        d.addCallbacks(cb, eb, callbackArgs=a, callbackKeywords=kw,</span><br><span class="line">            errbackArgs=a, errbackKeywords=kw)</span><br><span class="line">    <span class="keyword">if</span> isinstance(input, failure.Failure):</span><br><span class="line">        d.errback(input)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        d.callback(input)</span><br><span class="line">    <span class="keyword">return</span> d</span><br><span class="line"><span class="comment"># 这个是上面的升级版吧， 添加回调。 </span></span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(__name__) 全局的一个日志对象。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, *middlewares)</span>:</span></span><br><span class="line">    self.middlewares = middlewares</span><br><span class="line">    self.methods = defaultdict(list)</span><br><span class="line">    <span class="keyword">for</span> mw <span class="keyword">in</span> middlewares:</span><br><span class="line">        self._add_middleware(mw)</span><br><span class="line"><span class="comment"># 构造函数， 接受中间件列表， 构造方法的默认dict ， 添加中间件。</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@classmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_mwlist_from_settings</span><span class="params">(cls, settings)</span>:</span></span><br><span class="line">    <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"><span class="comment"># 这个方法什么鬼， 直接抛出异常？， 应该是写一个方法打个桩子吧， 以后可能后去完善它， 然后调用它的吧。 或者子类里面实现吧 。</span></span><br><span class="line"><span class="comment"># 如果子类不实现就抛出异常， 感觉应该是第二种情况， 这个其实和c++的接口是一样的。 强制子类去实现指定的方法。 </span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">from_settings</span><span class="params">(cls, settings, crawler=None)</span>:</span></span><br><span class="line">    mwlist = cls._get_mwlist_from_settings(settings)</span><br><span class="line">    middlewares = []</span><br><span class="line">    enabled = []</span><br><span class="line">    <span class="keyword">for</span> clspath <span class="keyword">in</span> mwlist:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            mwcls = load_object(clspath)</span><br><span class="line">            <span class="keyword">if</span> crawler <span class="keyword">and</span> hasattr(mwcls, <span class="string">'from_crawler'</span>):</span><br><span class="line">                mw = mwcls.from_crawler(crawler)</span><br><span class="line">            <span class="keyword">elif</span> hasattr(mwcls, <span class="string">'from_settings'</span>):</span><br><span class="line">                mw = mwcls.from_settings(settings)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                mw = mwcls()</span><br><span class="line">            middlewares.append(mw)</span><br><span class="line">            enabled.append(clspath)</span><br><span class="line">        <span class="keyword">except</span> NotConfigured <span class="keyword">as</span> e:</span><br><span class="line">            <span class="keyword">if</span> e.args:</span><br><span class="line">                clsname = clspath.split(<span class="string">'.'</span>)[<span class="number">-1</span>]</span><br><span class="line">                logger.warning(<span class="string">"Disabled %(clsname)s: %(eargs)s"</span>,</span><br><span class="line">                                &#123;<span class="string">'clsname'</span>: clsname, <span class="string">'eargs'</span>: e.args[<span class="number">0</span>]&#125;,</span><br><span class="line">                                extra=&#123;<span class="string">'crawler'</span>: crawler&#125;)</span><br><span class="line"></span><br><span class="line">    logger.info(<span class="string">"Enabled %(componentname)ss:\n%(enabledlist)s"</span>,</span><br><span class="line">                &#123;<span class="string">'componentname'</span>: cls.component_name,</span><br><span class="line">                    <span class="string">'enabledlist'</span>: pprint.pformat(enabled)&#125;,</span><br><span class="line">                extra=&#123;<span class="string">'crawler'</span>: crawler&#125;)</span><br><span class="line">    <span class="keyword">return</span> cls(*middlewares)</span><br><span class="line"><span class="comment"># 使用子类实现的方法_get_mwlist_from_settings 完成从settings里面获取中间件， 遍历中间件列表。 </span></span><br><span class="line"><span class="comment"># 如果中间件有from_crawler,from settings 这些方法，就调用下，去构造一个中间件对象。</span></span><br><span class="line"><span class="comment"># 添加到对应的中间件对象列表中去，这里mwlist只是中间件的类名字列表， middlearess存储的是中间件的对象。</span></span><br><span class="line"><span class="comment"># enabled 启用的中间件类列表。如果有异常， 说明配置文件给定的中间件不存在或者没法实例化。 </span></span><br><span class="line"><span class="comment"># 日志信息记录启动了那些中间件。返回中间件。</span></span><br><span class="line"><span class="meta">@classmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> cls.from_settings(crawler.settings, crawler)</span><br><span class="line"><span class="comment"># 调用对应的中间件方法from_settings 方法去完成类实例的创建</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_add_middleware</span><span class="params">(self, mw)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> hasattr(mw, <span class="string">'open_spider'</span>):</span><br><span class="line">        self.methods[<span class="string">'open_spider'</span>].append(mw.open_spider)</span><br><span class="line">    <span class="keyword">if</span> hasattr(mw, <span class="string">'close_spider'</span>):</span><br><span class="line">        self.methods[<span class="string">'close_spider'</span>].insert(<span class="number">0</span>, mw.close_spider)</span><br><span class="line"><span class="comment"># 添加中间件的房， 如果有open_spider，close_spider方法的话， 添加到对应方法去。 </span></span><br><span class="line"><span class="comment"># 我们这里可以发现， open是append的close是insert 0位置。 </span></span><br><span class="line"><span class="comment"># 也就是说， 如果一个中间件的open添加早那么他的close就后关闭的。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_process_parallel</span><span class="params">(self, methodname, obj, *args)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> process_parallel(self.methods[methodname], obj, *args)</span><br><span class="line"><span class="comment"># 处理平行的， 这个方法不知道具体怎么并行的。 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_process_chain</span><span class="params">(self, methodname, obj, *args)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> process_chain(self.methods[methodname], obj, *args)</span><br><span class="line">    <span class="comment"># 处理方法链</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_process_chain_both</span><span class="params">(self, cb_methodname, eb_methodname, obj, *args)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> process_chain_both(self.methods[cb_methodname], \</span><br><span class="line">        self.methods[eb_methodname], obj, *args)</span><br><span class="line"><span class="comment"># 处理成功和错误两个链</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> self._process_parallel(<span class="string">'open_spider'</span>, spider)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> self._process_parallel(<span class="string">'close_spider'</span>, spider)</span><br><span class="line"><span class="comment"># 打开爬虫， 关闭爬虫， 都是并行处理的。 </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从这个文件可以看出来， 我们要自己写个中间件的话， 要实现open_spider,close_spider, from_crawler，from_setting这些方法。</span></span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/python/spider/scrapy/20200704_ spidermw/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="崔永华（Andy）">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="崔永华的个人网站">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/07/python/spider/scrapy/20200704_ spidermw/" itemprop="url">
                  scrapy源码4：spidermw的源码分析
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-07-04T10:35:00+08:00">
                2020-07-04
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/爬虫/" itemprop="url" rel="index">
                    <span itemprop="name">爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          
            <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> six</span><br><span class="line"><span class="keyword">from</span> twisted.python.failure <span class="keyword">import</span> Failure</span><br><span class="line"><span class="comment"># 导入six包和导入failure</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy.middleware <span class="keyword">import</span> MiddlewareManager</span><br><span class="line"><span class="comment"># 这里导入了一个中间件管理的基类，应该适用于后续的继承的吧。 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy.utils.defer <span class="keyword">import</span> mustbe_deferred</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.conf <span class="keyword">import</span> build_component_list</span><br><span class="line"><span class="comment"># 这里从defer里面和conf里面导入2个方法。 先看看具体实现方法吧。 </span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mustbe_deferred</span><span class="params">(f, *args, **kw)</span>:</span></span><br><span class="line">    <span class="string">"""Same as twisted.internet.defer.maybeDeferred, but delay calling</span></span><br><span class="line"><span class="string">    callback/errback to next reactor loop</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        result = f(*args, **kw)</span><br><span class="line">    <span class="comment"># <span class="doctag">FIXME:</span> Hack to avoid introspecting tracebacks. This to speed up</span></span><br><span class="line">    <span class="comment"># processing of IgnoreRequest errors which are, by far, the most common</span></span><br><span class="line">    <span class="comment"># exception in Scrapy - see #125</span></span><br><span class="line">    <span class="keyword">except</span> IgnoreRequest <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> defer_fail(failure.Failure(e))</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">return</span> defer_fail(failure.Failure())</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> defer_result(result)</span><br><span class="line"><span class="comment"># 这个方法有点类似于defer_result 的意思。 不管啥请求都是调用了defer_fail或者defer_result . 都等100ms完成读写。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_component_list</span><span class="params">(compdict, custom=None, convert=update_classpath)</span>:</span></span><br><span class="line">    <span class="string">"""Compose a component list from a &#123; class: order &#125; dictionary."""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_check_components</span><span class="params">(complist)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> len(&#123;convert(c) <span class="keyword">for</span> c <span class="keyword">in</span> complist&#125;) != len(complist):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'Some paths in &#123;!r&#125; convert to the same object, '</span></span><br><span class="line">                             <span class="string">'please update your settings'</span>.format(complist))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_map_keys</span><span class="params">(compdict)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(compdict, BaseSettings):</span><br><span class="line">            compbs = BaseSettings()</span><br><span class="line">            <span class="keyword">for</span> k, v <span class="keyword">in</span> six.iteritems(compdict):</span><br><span class="line">                prio = compdict.getpriority(k)</span><br><span class="line">                <span class="keyword">if</span> compbs.getpriority(convert(k)) == prio:</span><br><span class="line">                    <span class="keyword">raise</span> ValueError(<span class="string">'Some paths in &#123;!r&#125; convert to the same '</span></span><br><span class="line">                                     <span class="string">'object, please update your settings'</span></span><br><span class="line">                                     <span class="string">''</span>.format(list(compdict.keys())))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    compbs.set(convert(k), v, priority=prio)</span><br><span class="line">            <span class="keyword">return</span> compbs</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            _check_components(compdict)</span><br><span class="line">            <span class="keyword">return</span> &#123;convert(k): v <span class="keyword">for</span> k, v <span class="keyword">in</span> six.iteritems(compdict)&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_validate_values</span><span class="params">(compdict)</span>:</span></span><br><span class="line">        <span class="string">"""Fail if a value in the components dict is not a real number or None."""</span></span><br><span class="line">        <span class="keyword">for</span> name, value <span class="keyword">in</span> six.iteritems(compdict):</span><br><span class="line">            <span class="keyword">if</span> value <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="keyword">not</span> isinstance(value, numbers.Real):</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">'Invalid value &#123;&#125; for component &#123;&#125;, please provide '</span> \</span><br><span class="line">                                 <span class="string">'a real number or None instead'</span>.format(value, name))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># BEGIN Backwards compatibility for old (base, custom) call signature</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(custom, (list, tuple)):</span><br><span class="line">        _check_components(custom)</span><br><span class="line">        <span class="keyword">return</span> type(custom)(convert(c) <span class="keyword">for</span> c <span class="keyword">in</span> custom)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> custom <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        compdict.update(custom)</span><br><span class="line">    <span class="comment"># END Backwards compatibility</span></span><br><span class="line"></span><br><span class="line">    _validate_values(compdict)</span><br><span class="line">    compdict = without_none_values(_map_keys(compdict))</span><br><span class="line">    <span class="keyword">return</span> [k <span class="keyword">for</span> k, v <span class="keyword">in</span> sorted(six.iteritems(compdict), key=itemgetter(<span class="number">1</span>))]</span><br><span class="line"><span class="comment"># 这个方法真的长 啊， 内部嵌套了几个方法。 </span></span><br><span class="line"><span class="comment"># 我们把内部嵌套的几个方法都分析下吧。 </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_check_components</span><span class="params">(complist)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> len(&#123;convert(c) <span class="keyword">for</span> c <span class="keyword">in</span> complist&#125;) != len(complist):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'Some paths in &#123;!r&#125; convert to the same object, '</span></span><br><span class="line">                             <span class="string">'please update your settings'</span>.format(complist))</span><br><span class="line"><span class="comment"># 这个方法从名字上看是检查组件的。先判断下长度相等不， 如果不等就抛出异常了。 </span></span><br><span class="line"><span class="comment"># 判断过程中用到了convert方法， 发现这个方法有默认值的。也就是convert使用默认的update_classpath方法处理，我们定位过去看看。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_classpath</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="string">"""Update a deprecated path from an object with its new location"""</span></span><br><span class="line">    <span class="keyword">for</span> prefix, replacement <span class="keyword">in</span> DEPRECATION_RULES:</span><br><span class="line">        <span class="keyword">if</span> path.startswith(prefix):</span><br><span class="line">            new_path = path.replace(prefix, replacement, <span class="number">1</span>)</span><br><span class="line">            warnings.warn(<span class="string">"`&#123;&#125;` class is deprecated, use `&#123;&#125;` instead"</span>.format(path, new_path),</span><br><span class="line">                          ScrapyDeprecationWarning)</span><br><span class="line">            <span class="keyword">return</span> new_path</span><br><span class="line">    <span class="keyword">return</span> path</span><br><span class="line"><span class="comment"># 这里有个规则啊 ，如果以旧的开头， 将他换成新的，然后提示一个警告信息。 返回新的路径。</span></span><br><span class="line"><span class="comment"># 规则我这里也粘贴过来吧。 </span></span><br><span class="line"></span><br><span class="line">DEPRECATION_RULES = [</span><br><span class="line">    (<span class="string">'scrapy.contrib_exp.downloadermiddleware.decompression.'</span>, <span class="string">'scrapy.downloadermiddlewares.decompression.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.contrib_exp.iterators.'</span>, <span class="string">'scrapy.utils.iterators.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.contrib.downloadermiddleware.'</span>, <span class="string">'scrapy.downloadermiddlewares.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.contrib.exporter.'</span>, <span class="string">'scrapy.exporters.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.contrib.linkextractors.'</span>, <span class="string">'scrapy.linkextractors.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.contrib.loader.processor.'</span>, <span class="string">'scrapy.loader.processors.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.contrib.loader.'</span>, <span class="string">'scrapy.loader.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.contrib.pipeline.'</span>, <span class="string">'scrapy.pipelines.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.contrib.spidermiddleware.'</span>, <span class="string">'scrapy.spidermiddlewares.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.contrib.spiders.'</span>, <span class="string">'scrapy.spiders.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.contrib.'</span>, <span class="string">'scrapy.extensions.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.command.'</span>, <span class="string">'scrapy.commands.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.dupefilter.'</span>, <span class="string">'scrapy.dupefilters.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.linkextractor.'</span>, <span class="string">'scrapy.linkextractors.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.telnet.'</span>, <span class="string">'scrapy.extensions.telnet.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.spider.'</span>, <span class="string">'scrapy.spiders.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.squeue.'</span>, <span class="string">'scrapy.squeues.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.statscol.'</span>, <span class="string">'scrapy.statscollectors.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.utils.decorator.'</span>, <span class="string">'scrapy.utils.decorators.'</span>),</span><br><span class="line">    (<span class="string">'scrapy.spidermanager.SpiderManager'</span>, <span class="string">'scrapy.spiderloader.SpiderLoader'</span>),</span><br><span class="line">]</span><br><span class="line"><span class="comment"># 看完这个方法，我们就明白了上面的代码</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_check_components</span><span class="params">(complist)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> len(&#123;convert(c) <span class="keyword">for</span> c <span class="keyword">in</span> complist&#125;) != len(complist):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'Some paths in &#123;!r&#125; convert to the same object, '</span></span><br><span class="line">                             <span class="string">'please update your settings'</span>.format(complist))</span><br><span class="line">    <span class="comment"># 这个他判定长度不等的情况一般是有新的旧的设置，重复导致的。 让你检查你的设置。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_map_keys</span><span class="params">(compdict)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(compdict, BaseSettings):</span><br><span class="line">        compbs = BaseSettings()</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> six.iteritems(compdict):</span><br><span class="line">            prio = compdict.getpriority(k)</span><br><span class="line">            <span class="keyword">if</span> compbs.getpriority(convert(k)) == prio:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">'Some paths in &#123;!r&#125; convert to the same '</span></span><br><span class="line">                                    <span class="string">'object, please update your settings'</span></span><br><span class="line">                                    <span class="string">''</span>.format(list(compdict.keys())))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                compbs.set(convert(k), v, priority=prio)</span><br><span class="line">        <span class="keyword">return</span> compbs</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        _check_components(compdict)</span><br><span class="line">        <span class="keyword">return</span> &#123;convert(k): v <span class="keyword">for</span> k, v <span class="keyword">in</span> six.iteritems(compdict)&#125;</span><br><span class="line"><span class="comment"># 这个判定下compdict是basesettings的子类， 如果是的话，构造一个basesettings， 遍历compdict</span></span><br><span class="line"><span class="comment"># 获取指定key的优先级prio, 如果优先级有相等的是要抛出异常的。其他情况下， 把优先级设置为compdict中指定的优先级。 </span></span><br><span class="line"><span class="comment"># 如果不是basesetting的子类。 就调用check_components去检查设置重复，然后返回一个dict对象。 </span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_validate_values</span><span class="params">(compdict)</span>:</span></span><br><span class="line">    <span class="string">"""Fail if a value in the components dict is not a real number or None."""</span></span><br><span class="line">    <span class="keyword">for</span> name, value <span class="keyword">in</span> six.iteritems(compdict):</span><br><span class="line">        <span class="keyword">if</span> value <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="keyword">not</span> isinstance(value, numbers.Real):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'Invalid value &#123;&#125; for component &#123;&#125;, please provide '</span> \</span><br><span class="line">                                <span class="string">'a real number or None instead'</span>.format(value, name))</span><br><span class="line">    <span class="comment"># 这个方法就是判定compdict里面value不是none或者real的话就抛出异常。 </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 几个内嵌的小方法看完了， 我们还是回到这个build_component_list 这个方法。 </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果custom是list,tuple的实例的话调用检查个数， 返回指定类对象。 这里返回一个list，或者元组。 </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果custome 不是none的话，就更新下comdict </span></span><br><span class="line"><span class="comment"># 验证下compdict,都是数值的。 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">without_none_values</span><span class="params">(iterable)</span>:</span></span><br><span class="line">    <span class="string">"""Return a copy of `iterable` with all `None` entries removed.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    If `iterable` is a mapping, return a dictionary where all pairs that have</span></span><br><span class="line"><span class="string">    value `None` have been removed.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> six.iteritems(iterable) <span class="keyword">if</span> v <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>&#125;</span><br><span class="line">    <span class="keyword">except</span> AttributeError:</span><br><span class="line">        <span class="keyword">return</span> type(iterable)((v <span class="keyword">for</span> v <span class="keyword">in</span> iterable <span class="keyword">if</span> v <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>))</span><br><span class="line">        <span class="comment"># 这个方法就是把none去掉。 如果是映射的话去掉。 </span></span><br><span class="line">        <span class="comment"># 这个方法的异常不知道为何要写这个。 方法吧， 可能这个方法其他地方还有其他用地。</span></span><br><span class="line"><span class="comment"># 然后这个方法返回一个排序的key数值， 具体排序方法使用了itemgetter(1) ，定位过去看下。 </span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Return a callable object that fetches the given item(s) from its operand.</span></span><br><span class="line"><span class="string">    After f = itemgetter(2), the call f(r) returns r[2].</span></span><br><span class="line"><span class="string">    After g = itemgetter(2, 5, 3), the call g(r) returns (r[2], r[5], r[3])</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"><span class="comment"># 这个说明够详细了吧。 根据value去排序key的上面的语句。 </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来就是爬虫中间件的具体实现代码了。 我们这里可以看到他继承了。 中间件管理类， 我们看看， 如果简单的话， 就先看看</span></span><br><span class="line"><span class="comment"># 如果复杂的话就先放放。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_mwlist_from_settings</span><span class="params">(cls, settings)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> build_component_list(settings.getwithbase(<span class="string">'SPIDER_MIDDLEWARES'</span>))</span><br><span class="line"><span class="comment"># 从名字上， 我们知道这个是从settings里面获取中间件的列表的。没问题的。 </span></span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">_add_middleware</span><span class="params">(self, mw)</span>:</span></span><br><span class="line">        super(SpiderMiddlewareManager, self)._add_middleware(mw)</span><br><span class="line">        <span class="keyword">if</span> hasattr(mw, <span class="string">'process_spider_input'</span>):</span><br><span class="line">            self.methods[<span class="string">'process_spider_input'</span>].append(mw.process_spider_input)</span><br><span class="line">        <span class="keyword">if</span> hasattr(mw, <span class="string">'process_spider_output'</span>):</span><br><span class="line">            self.methods[<span class="string">'process_spider_output'</span>].insert(<span class="number">0</span>, mw.process_spider_output)</span><br><span class="line">        <span class="keyword">if</span> hasattr(mw, <span class="string">'process_spider_exception'</span>):</span><br><span class="line">            self.methods[<span class="string">'process_spider_exception'</span>].insert(<span class="number">0</span>, mw.process_spider_exception)</span><br><span class="line">        <span class="keyword">if</span> hasattr(mw, <span class="string">'process_start_requests'</span>):</span><br><span class="line">            self.methods[<span class="string">'process_start_requests'</span>].insert(<span class="number">0</span>, mw.process_start_requests)</span><br><span class="line"><span class="comment"># 这个定义了一个添加中间件的方法</span></span><br><span class="line"><span class="comment"># 先调用基类的add方法， 然后判断判定是否有 process_spider_input 等等方法。 </span></span><br><span class="line"><span class="comment"># 如果有的话， 把这个中间件的方法添加到对应的方法链上去。 </span></span><br><span class="line"><span class="comment"># 这里有4个。 分别是。</span></span><br><span class="line">process_spider_input，</span><br><span class="line">process_spider_output</span><br><span class="line">process_spider_exception</span><br><span class="line">process_start_requests</span><br><span class="line"><span class="comment"># 我们这里可以看出， 如果我们自己要写爬虫中间件， 重点是这4个方法的。 切记切记。 </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># scrape_response 这个方法太长了。内部也嵌套了几个方法， 我们还是先看看内部的小方法吧。 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_spider_input</span><span class="params">(response)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> method <span class="keyword">in</span> self.methods[<span class="string">'process_spider_input'</span>]:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            result = method(response=response, spider=spider)</span><br><span class="line">            <span class="keyword">assert</span> result <span class="keyword">is</span> <span class="literal">None</span>, \</span><br><span class="line">                    <span class="string">'Middleware %s must returns None or '</span> \</span><br><span class="line">                    <span class="string">'raise an exception, got %s '</span> \</span><br><span class="line">                    % (fname(method), type(result))</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">return</span> scrape_func(Failure(), request, spider)</span><br><span class="line">    <span class="keyword">return</span> scrape_func(response, request, spider)</span><br><span class="line"><span class="comment"># 处理爬虫的中间件个各个 process_spider_input 方法。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_spider_exception</span><span class="params">(_failure)</span>:</span></span><br><span class="line">    exception = _failure.value</span><br><span class="line">    <span class="keyword">for</span> method <span class="keyword">in</span> self.methods[<span class="string">'process_spider_exception'</span>]:</span><br><span class="line">        result = method(response=response, exception=exception, spider=spider)</span><br><span class="line">        <span class="keyword">assert</span> result <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> _isiterable(result), \</span><br><span class="line">            <span class="string">'Middleware %s must returns None, or an iterable object, got %s '</span> % \</span><br><span class="line">            (fname(method), type(result))</span><br><span class="line">        <span class="keyword">if</span> result <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">    <span class="keyword">return</span> _failure </span><br><span class="line"><span class="comment"># 处理爬虫中间件的各个process_spider_exception方法。结果必须是none或者可迭代的。 </span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_spider_output</span><span class="params">(result)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> method <span class="keyword">in</span> self.methods[<span class="string">'process_spider_output'</span>]:</span><br><span class="line">        result = method(response=response, result=result, spider=spider)</span><br><span class="line">        <span class="keyword">assert</span> _isiterable(result), \</span><br><span class="line">            <span class="string">'Middleware %s must returns an iterable object, got %s '</span> % \</span><br><span class="line">            (fname(method), type(result))</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理爬虫中间件的各个process_spider_exception方法。结果可迭代的。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个scrape_response 方法， fname是获取到类的名字，  方法的名字</span></span><br><span class="line"></span><br><span class="line">dfd = mustbe_deferred(process_spider_input, response)</span><br><span class="line">dfd.addErrback(process_spider_exception)</span><br><span class="line">dfd.addCallback(process_spider_output)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这段代码， 创建延迟对象， 添加错误回调方法，添加成功回调方法。 </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_start_requests</span><span class="params">(self, start_requests, spider)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> self._process_chain(<span class="string">'process_start_requests'</span>, start_requests, spider)</span><br><span class="line"><span class="comment"># 这个方法， 就是处理开始请求的。调用了_process_chain处理链， 接受开始的请求和对应的爬虫。 具体还是需要去基类去看看这个方法的。</span></span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/python/spider/scrapy/20200703_ scraper/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="崔永华（Andy）">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="崔永华的个人网站">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/07/python/spider/scrapy/20200703_ scraper/" itemprop="url">
                  scrapy源码3：scraper的源码分析
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-07-03T10:35:00+08:00">
                2020-07-03
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/爬虫/" itemprop="url" rel="index">
                    <span itemprop="name">爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          
            <p>我们看看scraper.py文件吧。<br>从注释中我们可以看出这个scraper模块是实现爬虫组件去解析响应流并且提取数据的。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> deque</span><br><span class="line"><span class="comment"># 这2个就是日志的deque队列的导入。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> twisted.python.failure <span class="keyword">import</span> Failure</span><br><span class="line"><span class="keyword">from</span> twisted.internet <span class="keyword">import</span> defer</span><br><span class="line"><span class="comment"># 这2句，导入了一个Failure和一个defer延迟。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy.utils.defer <span class="keyword">import</span> defer_result, defer_succeed, parallel, iter_errback</span><br><span class="line"><span class="comment"># 这个从自己的工具类defer里面导入了好几个方法，基本看是并行，错误，成功，结果的一些相关方法。 我们定位过去一个一个分析下。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">defer_result</span><span class="params">(result)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(result, defer.Deferred):</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line">    <span class="keyword">elif</span> isinstance(result, failure.Failure):</span><br><span class="line">        <span class="keyword">return</span> defer_fail(result)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> defer_succeed(result)</span><br><span class="line">    <span class="comment"># 这里对result进行判定， 如果是Deferred对象，那就返回，如果是Failure结果 返回defer_fail(result) 这个defer_fail应该是对这个错误的result解析的吧。先放放</span></span><br><span class="line">    <span class="comment"># 其他的情况就直接使用defer_succeed去解析。既然这里提到了defer_fail，defer_succeed 2个方法， 那我们干脆就先看看这2个方法做了啥。</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">defer_fail</span><span class="params">(_failure)</span>:</span></span><br><span class="line">    <span class="string">"""Same as twisted.internet.defer.fail but delay calling errback until</span></span><br><span class="line"><span class="string">    next reactor loop</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    It delays by 100ms so reactor has a chance to go trough readers and writers</span></span><br><span class="line"><span class="string">    before attending pending delayed calls, so do not set delay to zero.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    d = defer.Deferred()</span><br><span class="line">    reactor.callLater(<span class="number">0.1</span>, d.errback, _failure)</span><br><span class="line">    <span class="keyword">return</span> d</span><br><span class="line">    <span class="comment"># 这个是google翻译了下twisted.internet.defer.fail相同，但延迟调用errback直到下一个反应器回路它延迟了100ms，所以反应堆有机会通过读写在等待延迟呼叫之前，所以不要将延迟设置为零</span></span><br><span class="line">    <span class="comment"># 我们从上面可以知道，他故意延迟0.1为了读写操作的。</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">defer_succeed</span><span class="params">(result)</span>:</span></span><br><span class="line">    <span class="string">"""Same as twisted.internet.defer.succeed but delay calling callback until</span></span><br><span class="line"><span class="string">    next reactor loop</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    It delays by 100ms so reactor has a chance to go trough readers and writers</span></span><br><span class="line"><span class="string">    before attending pending delayed calls, so do not set delay to zero.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    d = defer.Deferred()</span><br><span class="line">    reactor.callLater(<span class="number">0.1</span>, d.callback, result)</span><br><span class="line">    <span class="keyword">return</span> d</span><br><span class="line">    <span class="comment"># 这个方法不多解释了。 和上面的那个是一样的。 </span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parallel</span><span class="params">(iterable, count, callable, *args, **named)</span>:</span></span><br><span class="line">    <span class="string">"""Execute a callable over the objects in the given iterable, in parallel,</span></span><br><span class="line"><span class="string">    using no more than ``count`` concurrent calls.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Taken from: http://jcalderone.livejournal.com/24285.html</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    coop = task.Cooperator()</span><br><span class="line">    work = (callable(elem, *args, **named) <span class="keyword">for</span> elem <span class="keyword">in</span> iterable)</span><br><span class="line">    <span class="keyword">return</span> defer.DeferredList([coop.coiterate(work) <span class="keyword">for</span> _ <span class="keyword">in</span> range(count)])</span><br><span class="line">    <span class="comment"># 这个看的不太懂。 就是解决并发问题的。 去了http://jcalderone.livejournal.com/24285.html 也没有看懂。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iter_errback</span><span class="params">(iterable, errback, *a, **kw)</span>:</span></span><br><span class="line">    <span class="string">"""Wraps an iterable calling an errback if an error is caught while</span></span><br><span class="line"><span class="string">    iterating it.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    it = iter(iterable)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">yield</span> next(it)</span><br><span class="line">        <span class="keyword">except</span> StopIteration:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            errback(failure.Failure(), *a, **kw)</span><br><span class="line">    <span class="comment"># 迭代处理iterable这个对象，google翻译下吧： 如果在迭代时捕获到错误，则可以包装一个可调用的回调函数。这个方法一直迭代，如果错误就使用errback包装一个可回调的函数。 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy.utils.spider <span class="keyword">import</span> iterate_spider_output</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">iterate_spider_output</span><span class="params">(result)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> arg_to_iter(result)</span><br><span class="line">    <span class="comment"># 这个方法定位到另一个位置了。 我们追踪过去看看</span></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">arg_to_iter</span><span class="params">(arg)</span>:</span></span><br><span class="line">    <span class="string">"""Convert an argument to an iterable. The argument can be a None, single</span></span><br><span class="line"><span class="string">    value, or an iterable.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Exception: if arg is a dict, [arg] will be returned</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> arg <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line">    <span class="keyword">elif</span> <span class="keyword">not</span> isinstance(arg, _ITERABLE_SINGLE_VALUES) <span class="keyword">and</span> hasattr(arg, <span class="string">'__iter__'</span>):</span><br><span class="line">        <span class="keyword">return</span> arg</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> [arg]   </span><br><span class="line">    <span class="comment"># 将对象转化为可迭代的对象。</span></span><br><span class="line">    <span class="comment"># 如果是none返回[], 如果是不可迭代就返回[arg] 本身迭代的就返回自身。</span></span><br><span class="line">    _ITERABLE_SINGLE_VALUES = dict, BaseItem, six.text_type, bytes</span><br><span class="line">    <span class="comment"># 这里是不是需要还需要判定下arg是不是有__next__呢。 </span></span><br><span class="line"><span class="keyword">from</span> scrapy.utils.misc <span class="keyword">import</span> load_object 这个<span class="number">01</span>，<span class="number">02</span>的文档都提到了就是将str转对象的。</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy.utils.log <span class="keyword">import</span> logformatter_adapter, failure_to_exc_info</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个是基础日志的。我们也看看吧。 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">logformatter_adapter</span><span class="params">(logkws)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Helper that takes the dictionary output from the methods in LogFormatter</span></span><br><span class="line"><span class="string">    and adapts it into a tuple of positional arguments for logger.log calls,</span></span><br><span class="line"><span class="string">    handling backward compatibility as well.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> &#123;<span class="string">'level'</span>, <span class="string">'msg'</span>, <span class="string">'args'</span>&#125; &lt;= set(logkws):</span><br><span class="line">        warnings.warn(<span class="string">'Missing keys in LogFormatter method'</span>,</span><br><span class="line">                      ScrapyDeprecationWarning)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'format'</span> <span class="keyword">in</span> logkws:</span><br><span class="line">        warnings.warn(<span class="string">'`format` key in LogFormatter methods has been '</span></span><br><span class="line">                      <span class="string">'deprecated, use `msg` instead'</span>,</span><br><span class="line">                      ScrapyDeprecationWarning)</span><br><span class="line"></span><br><span class="line">    level = logkws.get(<span class="string">'level'</span>, logging.INFO)</span><br><span class="line">    message = logkws.get(<span class="string">'format'</span>, logkws.get(<span class="string">'msg'</span>))</span><br><span class="line">    <span class="comment"># <span class="doctag">NOTE:</span> This also handles 'args' being an empty dict, that case doesn't</span></span><br><span class="line">    <span class="comment"># play well in logger.log calls</span></span><br><span class="line">    args = logkws <span class="keyword">if</span> <span class="keyword">not</span> logkws.get(<span class="string">'args'</span>) <span class="keyword">else</span> logkws[<span class="string">'args'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (level, message, args)</span><br><span class="line"><span class="comment"># 这个方法是个适配器，将logkws字典对象最终返回一个元组，日志级别，信息，和详细参数。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">failure_to_exc_info</span><span class="params">(failure)</span>:</span></span><br><span class="line">    <span class="string">"""Extract exc_info from Failure instances"""</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(failure, Failure):</span><br><span class="line">        <span class="keyword">return</span> (failure.type, failure.value, failure.getTracebackObject())</span><br><span class="line"><span class="comment"># 方法比较简单， 用于提取错误实例的信息。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> CloseSpider, DropItem, IgnoreRequest</span><br><span class="line"><span class="comment"># 这里从异常类导入几个异常吧。 我们也定位过去吧。 </span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DropItem</span><span class="params">(Exception)</span>:</span></span><br><span class="line">    <span class="string">"""Drop item from the item pipeline"""</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"> <span class="class"><span class="keyword">class</span> <span class="title">CloseSpider</span><span class="params">(Exception)</span>:</span></span><br><span class="line">    <span class="string">"""Raise this from callbacks to request the spider to be closed"""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, reason=<span class="string">'cancelled'</span>)</span>:</span></span><br><span class="line">        super(CloseSpider, self).__init__()</span><br><span class="line">        self.reason = reason</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IgnoreRequest</span><span class="params">(Exception)</span>:</span></span><br><span class="line">    <span class="string">"""Indicates a decision was made not to process a request"""</span></span><br><span class="line"><span class="comment"># 这三个基本都是异常类而已，继承了exception,无实质代码。</span></span><br><span class="line"><span class="comment"># dropitem: item被丢弃的异常。 </span></span><br><span class="line"><span class="comment"># closespider：关闭爬虫的异常。</span></span><br><span class="line"><span class="comment"># IgnoreRequest:忽略请求的异常。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> signals <span class="comment"># 这里就是导入那几个信号了。 </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> Request, Response <span class="comment"># 这个导入了请求和响应类。</span></span><br><span class="line"><span class="keyword">from</span> scrapy.core.spidermw <span class="keyword">import</span> SpiderMiddlewareManager <span class="comment"># 导入了爬虫中间件管理</span></span><br><span class="line"><span class="keyword">from</span> scrapy.utils.request <span class="keyword">import</span> referer_str <span class="comment"># 这个不清楚。 定位过去看下吧。 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">referer_str</span><span class="params">(request)</span>:</span></span><br><span class="line">    <span class="string">""" Return Referer HTTP header suitable for logging. """</span></span><br><span class="line">    referrer = request.headers.get(<span class="string">'Referer'</span>)</span><br><span class="line">    <span class="keyword">if</span> referrer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> referrer</span><br><span class="line">    <span class="keyword">return</span> to_native_str(referrer, errors=<span class="string">'replace'</span>)</span><br><span class="line">    <span class="comment"># 从请求头信息里面获取referer信息。</span></span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(__name__) <span class="comment"># 全局的日志对象</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 上面的包分析完毕了。 我们看看下面的类吧，有2个一个是slot，一个是scraper。一个一个看吧。 </span></span><br><span class="line">slot的方法看下</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, max_active_size=<span class="number">5000000</span>)</span>:</span></span><br><span class="line">        self.max_active_size = max_active_size</span><br><span class="line">        self.queue = deque()</span><br><span class="line">        self.active = set()</span><br><span class="line">        self.active_size = <span class="number">0</span></span><br><span class="line">        self.itemproc_size = <span class="number">0</span></span><br><span class="line">        self.closing = <span class="literal">None</span></span><br><span class="line">    <span class="comment"># 这里设置了，最大活动大小，默认值为5000000， 这个值为何不放到默认配置文件里面呢。疑惑下。</span></span><br><span class="line">    <span class="comment"># 构造一个deques,使用集合去存储活动的， 活动的大小开始为0，itemproc_size item 处理的大小，关闭状态为none.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_response_request</span><span class="params">(self, response, request)</span>:</span></span><br><span class="line">        deferred = defer.Deferred()</span><br><span class="line">        self.queue.append((response, request, deferred))</span><br><span class="line">        <span class="keyword">if</span> isinstance(response, Response):</span><br><span class="line">            self.active_size += max(len(response.body), self.MIN_RESPONSE_SIZE)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.active_size += self.MIN_RESPONSE_SIZE</span><br><span class="line">        <span class="keyword">return</span> deferred</span><br><span class="line">        <span class="comment"># 这个方法从名字上看 ，应该是添加响应请求吧，</span></span><br><span class="line">        <span class="comment"># 创建一个defer对象，队列里面添加一个(response,request,deferred)元祖，如果response shi REsposne的示例的话</span></span><br><span class="line">        <span class="comment"># 活动的大小就是原来活动的大小+ body的长度h或者最小响应的大小。</span></span><br><span class="line">        <span class="comment"># 否则，就设置为最小的响应大小。放回那个deferred.</span></span><br><span class="line">     </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">next_response_request_deferred</span><span class="params">(self)</span>:</span></span><br><span class="line">        response, request, deferred = self.queue.popleft()</span><br><span class="line">        self.active.add(request)</span><br><span class="line">        <span class="keyword">return</span> response, request, deferred</span><br><span class="line">    <span class="comment"># 从队列中popleft一个元组，活动请求添加request,返回一个元组，response,request,deferred</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">finish_response</span><span class="params">(self, response, request)</span>:</span></span><br><span class="line">    self.active.remove(request)</span><br><span class="line">    <span class="keyword">if</span> isinstance(response, Response):</span><br><span class="line">        self.active_size -= max(len(response.body), self.MIN_RESPONSE_SIZE)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self.active_size -= self.MIN_RESPONSE_SIZE</span><br><span class="line">    <span class="comment"># 完成响应的话， 就从active活动列表中移除这个请求，active_size 减去对应大小。</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_idle</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">not</span> (self.queue <span class="keyword">or</span> self.active)   </span><br><span class="line">        <span class="comment"># 是否空闲的判断， 如果队列不为空， 或者active不为空。</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">needs_backout</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.active_size &gt; self.max_active_size    </span><br><span class="line">    <span class="comment"># 判断是否超限了。 </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面看看这个scraper类吧。 </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, crawler)</span>:</span></span><br><span class="line">        self.slot = <span class="literal">None</span></span><br><span class="line">        self.spidermw = SpiderMiddlewareManager.from_crawler(crawler)</span><br><span class="line">        itemproc_cls = load_object(crawler.settings[<span class="string">'ITEM_PROCESSOR'</span>])</span><br><span class="line">        self.itemproc = itemproc_cls.from_crawler(crawler)</span><br><span class="line">        self.concurrent_items = crawler.settings.getint(<span class="string">'CONCURRENT_ITEMS'</span>)</span><br><span class="line">        self.crawler = crawler</span><br><span class="line">        self.signals = crawler.signals</span><br><span class="line">        self.logformatter = crawler.logformatter</span><br><span class="line"><span class="comment"># 这个是初始化了，爬虫中间件从crawler获取，item处理类从crawler.settings获取。然后获取一个item处理类的对象。</span></span><br><span class="line"><span class="comment"># 并发item数量，信号和日志formatter设置都是从crawler获取。</span></span><br><span class="line"></span><br><span class="line"><span class="meta">  @defer.inlineCallbacks</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        <span class="string">"""Open the given spider for scraping and allocate resources for it"""</span></span><br><span class="line">        self.slot = Slot()</span><br><span class="line">        <span class="keyword">yield</span> self.itemproc.open_spider(spider)</span><br><span class="line">    <span class="comment"># 这个方法就是打开给定的爬虫，并分配指定的资源，</span></span><br><span class="line">    <span class="comment"># 创建一个slot，然后调用对应的itemproessor类创建的处理类去打开爬虫。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">    <span class="string">"""Close a spider being scraped and release its resources"""</span></span><br><span class="line">    slot = self.slot</span><br><span class="line">    slot.closing = defer.Deferred()</span><br><span class="line">    slot.closing.addCallback(self.itemproc.close_spider)</span><br><span class="line">    self._check_if_closing(spider, slot)</span><br><span class="line">    <span class="keyword">return</span> slot.closing  </span><br><span class="line">    <span class="comment"># 关闭爬虫并且释放资源。</span></span><br><span class="line">    <span class="comment"># 获取slot， 然后给slot添加一个closing的事件，然后放回方法。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_idle</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="string">"""Return True if there isn't any more spiders to process"""</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">not</span> self.slot </span><br><span class="line">    <span class="comment"># 如果没有爬虫去处理了。 就返回true了。 </span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_check_if_closing</span><span class="params">(self, spider, slot)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> slot.closing <span class="keyword">and</span> slot.is_idle():</span><br><span class="line">        slot.closing.callback(spider)        </span><br><span class="line">    <span class="comment"># 如果closing不为空，不为空闲，  就调用指定spider的关闭回调。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">enqueue_scrape</span><span class="params">(self, response, request, spider)</span>:</span></span><br><span class="line">    slot = self.slot</span><br><span class="line">    dfd = slot.add_response_request(response, request)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">finish_scraping</span><span class="params">(_)</span>:</span></span><br><span class="line">        slot.finish_response(response, request)</span><br><span class="line">        self._check_if_closing(spider, slot)</span><br><span class="line">        self._scrape_next(spider, slot)</span><br><span class="line">        <span class="keyword">return</span> _</span><br><span class="line">    dfd.addBoth(finish_scraping)</span><br><span class="line">    dfd.addErrback(</span><br><span class="line">        <span class="keyword">lambda</span> f: logger.error(<span class="string">'Scraper bug processing %(request)s'</span>,</span><br><span class="line">                                &#123;<span class="string">'request'</span>: request&#125;,</span><br><span class="line">                                exc_info=failure_to_exc_info(f),</span><br><span class="line">                                extra=&#123;<span class="string">'spider'</span>: spider&#125;))</span><br><span class="line">    self._scrape_next(spider, slot)</span><br><span class="line">    <span class="keyword">return</span> dfd</span><br><span class="line">    <span class="comment"># 调用add_response_request添加返回一个defferd对象，定义一个完成的方法，给成功和失败都添加一个finish_scraping的回调。</span></span><br><span class="line">    <span class="comment"># 给错误的在添加一个匿名的回调方法。</span></span><br><span class="line">    <span class="comment"># 调用_scrape_next 处理下一个。 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_scrape_next</span><span class="params">(self, spider, slot)</span>:</span></span><br><span class="line">    <span class="keyword">while</span> slot.queue:</span><br><span class="line">        response, request, deferred = slot.next_response_request_deferred()</span><br><span class="line">        self._scrape(response, request, spider).chainDeferred(deferred)   </span><br><span class="line">    <span class="comment"># 这里如果slot的queue有内容的haunted， 就一直循环下去， 调用_scrape去处理。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_scrape</span><span class="params">(self, response, request, spider)</span>:</span></span><br><span class="line">    <span class="string">"""Handle the downloaded response or failure through the spider</span></span><br><span class="line"><span class="string">    callback/errback"""</span></span><br><span class="line">    <span class="keyword">assert</span> isinstance(response, (Response, Failure))</span><br><span class="line"></span><br><span class="line">    dfd = self._scrape2(response, request, spider) <span class="comment"># returns spiders processed output</span></span><br><span class="line">    dfd.addErrback(self.handle_spider_error, request, response, spider)</span><br><span class="line">    dfd.addCallback(self.handle_spider_output, request, response, spider)</span><br><span class="line">    <span class="keyword">return</span> dfd    </span><br><span class="line">    <span class="comment"># 这个方法就是处理下载响应或者失败，通过给爬虫指定的成功和错误的回调方法。</span></span><br><span class="line">    <span class="comment"># 先断言这个是响应流或者failure，调用_scrape2获取爬虫处理的输出</span></span><br><span class="line">    <span class="comment"># 添加错误回调和成功回调。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_scrape2</span><span class="params">(self, request_result, request, spider)</span>:</span></span><br><span class="line">    <span class="string">"""Handle the different cases of request's result been a Response or a</span></span><br><span class="line"><span class="string">    Failure"""</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(request_result, Failure):</span><br><span class="line">        <span class="keyword">return</span> self.spidermw.scrape_response(</span><br><span class="line">            self.call_spider, request_result, request, spider)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># <span class="doctag">FIXME:</span> don't ignore errors in spider middleware</span></span><br><span class="line">        dfd = self.call_spider(request_result, request, spider)</span><br><span class="line">        <span class="keyword">return</span> dfd.addErrback(</span><br><span class="line">            self._log_download_errors, request_result, request, spider)</span><br><span class="line">    <span class="comment"># 如果响应是成功的的。调用自己的爬虫中间件去处理响应。如果是错误的，调用call_spider方法，给dfd添加一个错误的回调。 </span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">call_spider</span><span class="params">(self, result, request, spider)</span>:</span></span><br><span class="line">    result.request = request</span><br><span class="line">    dfd = defer_result(result)</span><br><span class="line">    dfd.addCallbacks(request.callback <span class="keyword">or</span> spider.parse, request.errback)</span><br><span class="line">    <span class="keyword">return</span> dfd.addCallback(iterate_spider_output)</span><br><span class="line">    defer_result 这个方法我们上面已经看了。 主要是等<span class="number">100</span>ms读写的。 添加成功的回调。</span><br><span class="line">    <span class="comment"># 这个地方注意了。 先使用request。callback , 如果没有指定的话，默认采用spider.parse方法。</span></span><br><span class="line">    <span class="comment"># 这就是我们的爬虫为何使用parse方法解析response的原因了。 </span></span><br><span class="line">    <span class="comment"># 添加一个成功回调。 iterate_spider_output 这个上面已经看过了， 就是返回一个可迭代的对象。 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle_spider_error</span><span class="params">(self, _failure, request, response, spider)</span>:</span></span><br><span class="line">    exc = _failure.value</span><br><span class="line">    <span class="keyword">if</span> isinstance(exc, CloseSpider):</span><br><span class="line">        self.crawler.engine.close_spider(spider, exc.reason <span class="keyword">or</span> <span class="string">'cancelled'</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    logger.error(</span><br><span class="line">        <span class="string">"Spider error processing %(request)s (referer: %(referer)s)"</span>,</span><br><span class="line">        &#123;<span class="string">'request'</span>: request, <span class="string">'referer'</span>: referer_str(request)&#125;,</span><br><span class="line">        exc_info=failure_to_exc_info(_failure),</span><br><span class="line">        extra=&#123;<span class="string">'spider'</span>: spider&#125;</span><br><span class="line">    )</span><br><span class="line">    self.signals.send_catch_log(</span><br><span class="line">        signal=signals.spider_error,</span><br><span class="line">        failure=_failure, response=response,</span><br><span class="line">        spider=spider</span><br><span class="line">    )</span><br><span class="line">    self.crawler.stats.inc_value(</span><br><span class="line">        <span class="string">"spider_exceptions/%s"</span> % _failure.value.__class__.__name__,</span><br><span class="line">        spider=spider</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># 这个方法就是处理爬虫错误的 ， 如果是关闭爬虫异常， 调用对应引擎去关闭爬虫，返回</span></span><br><span class="line">    <span class="comment"># 其他情况，就记录下日志信息。 发送对应的爬虫错误信号， 统计信息的添加。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle_spider_output</span><span class="params">(self, result, request, response, spider)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> result:</span><br><span class="line">        <span class="keyword">return</span> defer_succeed(<span class="literal">None</span>)</span><br><span class="line">    it = iter_errback(result, self.handle_spider_error, request, response, spider)</span><br><span class="line">    dfd = parallel(it, self.concurrent_items,</span><br><span class="line">        self._process_spidermw_output, request, response, spider)</span><br><span class="line">    <span class="keyword">return</span> dfd   </span><br><span class="line">    <span class="comment"># 处理爬虫的输出，如果结果不为空 调用defer_succeed,错误的话调用错误回调，平行处理， _process_spidermw_output去处理</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_process_spidermw_output</span><span class="params">(self, output, request, response, spider)</span>:</span></span><br><span class="line">    <span class="string">"""Process each Request/Item (given in the output parameter) returned</span></span><br><span class="line"><span class="string">    from the given spider</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(output, Request):</span><br><span class="line">        self.crawler.engine.crawl(request=output, spider=spider)</span><br><span class="line">    <span class="keyword">elif</span> isinstance(output, (BaseItem, dict)):</span><br><span class="line">        self.slot.itemproc_size += <span class="number">1</span></span><br><span class="line">        dfd = self.itemproc.process_item(output, spider)</span><br><span class="line">        dfd.addBoth(self._itemproc_finished, output, response, spider)</span><br><span class="line">        <span class="keyword">return</span> dfd</span><br><span class="line">    <span class="keyword">elif</span> output <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        typename = type(output).__name__</span><br><span class="line">        logger.error(<span class="string">'Spider must return Request, BaseItem, dict or None, '</span></span><br><span class="line">                        <span class="string">'got %(typename)r in %(request)s'</span>,</span><br><span class="line">                        &#123;<span class="string">'request'</span>: request, <span class="string">'typename'</span>: typename&#125;,</span><br><span class="line">                        extra=&#123;<span class="string">'spider'</span>: spider&#125;)</span><br><span class="line">    <span class="comment"># 处理每个请求或者从给定的爬虫得到的item</span></span><br><span class="line">    <span class="comment"># 如果output是个请求的话， 调用engine.crawl抓取。 </span></span><br><span class="line">    <span class="comment"># 如果是baseitem或者dict的话， 处理个数加1，调用item处理类的process_item去处理item。</span></span><br><span class="line">    <span class="comment"># 添加处理完毕事件。 </span></span><br><span class="line">    <span class="comment"># 其他请求输出日志。 报告你的返回类型不是给定的item类或者字典类。 或者请求。 </span></span><br><span class="line">    <span class="comment"># 这里就是限定了。 我们爬虫里面的parse方法只能返回这3类的原因了。 </span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_log_download_errors</span><span class="params">(self, spider_failure, download_failure, request, spider)</span>:</span></span><br><span class="line">    <span class="string">"""Log and silence errors that come from the engine (typically download</span></span><br><span class="line"><span class="string">    errors that got propagated thru here)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> (isinstance(download_failure, Failure) <span class="keyword">and</span></span><br><span class="line">            <span class="keyword">not</span> download_failure.check(IgnoreRequest)):</span><br><span class="line">        <span class="keyword">if</span> download_failure.frames:</span><br><span class="line">            logger.error(<span class="string">'Error downloading %(request)s'</span>,</span><br><span class="line">                            &#123;<span class="string">'request'</span>: request&#125;,</span><br><span class="line">                            exc_info=failure_to_exc_info(download_failure),</span><br><span class="line">                            extra=&#123;<span class="string">'spider'</span>: spider&#125;)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            errmsg = download_failure.getErrorMessage()</span><br><span class="line">            <span class="keyword">if</span> errmsg:</span><br><span class="line">                logger.error(<span class="string">'Error downloading %(request)s: %(errmsg)s'</span>,</span><br><span class="line">                                &#123;<span class="string">'request'</span>: request, <span class="string">'errmsg'</span>: errmsg&#125;,</span><br><span class="line">                                extra=&#123;<span class="string">'spider'</span>: spider&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> spider_failure <span class="keyword">is</span> <span class="keyword">not</span> download_failure:</span><br><span class="line">        <span class="keyword">return</span> spider_failure    </span><br><span class="line">    <span class="comment"># 这里定义个方法下载错误的， 如果是错误 并且不是ignorerequest的话进入if块。</span></span><br><span class="line">    <span class="comment"># 如果错误frames不为空，记录错误信息。</span></span><br><span class="line">    <span class="comment"># 否则调用geterrmessage方法，记录错误。</span></span><br><span class="line">    <span class="comment"># 如果错误不是下载错误，返回爬虫的错误。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_itemproc_finished</span><span class="params">(self, output, item, response, spider)</span>:</span></span><br><span class="line">    <span class="string">"""ItemProcessor finished for the given ``item`` and returned ``output``</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    self.slot.itemproc_size -= <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(output, Failure):</span><br><span class="line">        ex = output.value</span><br><span class="line">        <span class="keyword">if</span> isinstance(ex, DropItem):</span><br><span class="line">            logkws = self.logformatter.dropped(item, ex, response, spider)</span><br><span class="line">            logger.log(*logformatter_adapter(logkws), extra=&#123;<span class="string">'spider'</span>: spider&#125;)</span><br><span class="line">            <span class="keyword">return</span> self.signals.send_catch_log_deferred(</span><br><span class="line">                signal=signals.item_dropped, item=item, response=response,</span><br><span class="line">                spider=spider, exception=output.value)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            logger.error(<span class="string">'Error processing %(item)s'</span>, &#123;<span class="string">'item'</span>: item&#125;,</span><br><span class="line">                            exc_info=failure_to_exc_info(output),</span><br><span class="line">                            extra=&#123;<span class="string">'spider'</span>: spider&#125;)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        logkws = self.logformatter.scraped(output, response, spider)</span><br><span class="line">        logger.log(*logformatter_adapter(logkws), extra=&#123;<span class="string">'spider'</span>: spider&#125;)</span><br><span class="line">        <span class="keyword">return</span> self.signals.send_catch_log_deferred(</span><br><span class="line">            signal=signals.item_scraped, item=output, response=response,</span><br><span class="line">            spider=spider)</span><br><span class="line">    <span class="comment"># itemprocess处理类结束，如果输出㐊错误。 判定他是不是dropitem。  分别记录日志。  </span></span><br><span class="line">    <span class="comment"># 正常情况下，记录日志 。通过日志适配器将logkws 转出logger.log方法接受的参数。 </span></span><br><span class="line">    <span class="comment"># 发送itemscraped信号。</span></span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/python/spider/scrapy/20200701_scheduler/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="崔永华（Andy）">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="崔永华的个人网站">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/07/python/spider/scrapy/20200701_scheduler/" itemprop="url">
                  scrapy源码2：scheduler的源码分析
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-07-01T10:35:00+08:00">
                2020-07-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/爬虫/" itemprop="url" rel="index">
                    <span itemprop="name">爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          
            <h3 id="scheduler核心"><a href="#scheduler核心" class="headerlink" title="scheduler核心"></a>scheduler核心</h3><p>Scheduler主要负责scrapy请求队列的管理，即进队与出队。进一步来说，会涉及到队列的选择，队列去重，序列化。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from_crawler(cls, crawler):</span><br><span class="line">        settings = crawler.settings</span><br><span class="line">        dupefilter_cls = load_object(settings[<span class="string">'DUPEFILTER_CLASS'</span>])</span><br><span class="line">        dupefilter = dupefilter_cls.from_settings(settings)</span><br><span class="line">        pqclass = load_object(settings[<span class="string">'SCHEDULER_PRIORITY_QUEUE'</span>])</span><br><span class="line">        dqclass = load_object(settings[<span class="string">'SCHEDULER_DISK_QUEUE'</span>])</span><br><span class="line">        mqclass = load_object(settings[<span class="string">'SCHEDULER_MEMORY_QUEUE'</span>])</span><br><span class="line">        logunser = settings.getbool(<span class="string">'LOG_UNSERIALIZABLE_REQUESTS'</span>, settings.getbool(<span class="string">'SCHEDULER_DEBUG'</span>))</span><br><span class="line">        <span class="keyword">return</span> cls(dupefilter, jobdir=job_dir(settings), logunser=logunser,</span><br><span class="line">                   stats=crawler.stats, pqclass=pqclass, dqclass=dqclass, mqclass=mqclass)</span><br></pre></td></tr></table></figure>
<p>创建了4个对象，分别是dupefilter,pqclass,dqclass,mqclass。</p>
<h4 id="1-dupefilter过滤器（url去重）"><a href="#1-dupefilter过滤器（url去重）" class="headerlink" title="1. dupefilter过滤器（url去重）"></a>1. dupefilter过滤器（url去重）</h4><p>DUPEFILTER_CLASS = ‘scrapy.dupefilters.RFPDupeFilter’这个类的含义是”Request Fingerprint duplicates filter”，请求指纹副本过滤。也就是对每个request请求做一个指纹，保证相同的请求有相同的指纹。对重复的请求进行过滤。包含查询字符串、cookies字段的相同url也会被去重。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RFPDupeFilter</span><span class="params">(BaseDupeFilter)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">request_seen</span><span class="params">(self, request)</span>:</span></span><br><span class="line">        fp = self.request_fingerprint(request)</span><br><span class="line">        <span class="keyword">if</span> fp <span class="keyword">in</span> self.fingerprints:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        self.fingerprints.add(fp)</span><br><span class="line">        <span class="keyword">if</span> self.file:</span><br><span class="line">            self.file.write(fp + os.linesep)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">request_fingerprint</span><span class="params">(self, request)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> request_fingerprint(request)</span><br></pre></td></tr></table></figure>
<p>scrapy默认的去重方案：利用request生成fingerprint, 存入set，每次利用set判断，如果用了 disk queue 追加至文件</p>
<h4 id="2-pqclass优先级队列"><a href="#2-pqclass优先级队列" class="headerlink" title="2. pqclass优先级队列"></a>2. pqclass优先级队列</h4><p>SCHEDULER_PRIORITY_QUEUE = ‘queuelib.PriorityQueue’这是一个优先级队列，使用的是开源的第三方queuelib.它的作用就是对request请求按优先级进行排序，这样我们可以对不同重要性的URL指定优先级（通过设置Request的priority属性）。优先级是一个整数，虽然queuelib使用小的数做为高优化级，但是由于scheduler入队列时取了负值，所以对于我们来说，数值越大优先级越高。</p>
<h4 id="3-dqclass支持序列化的后进先出的磁盘队列"><a href="#3-dqclass支持序列化的后进先出的磁盘队列" class="headerlink" title="3. dqclass支持序列化的后进先出的磁盘队列"></a>3. dqclass支持序列化的后进先出的磁盘队列</h4><p>SCHEDULER_DISK_QUEUE = ‘scrapy.squeues.PickleLifoDiskQueue’<br>这是一个支持序列化的后进先出的磁盘队列。主要用来帮助我们在停止爬虫后可以接着上一次继续开始爬虫。</p>
<h4 id="4-mqclass后进先出的内存队列"><a href="#4-mqclass后进先出的内存队列" class="headerlink" title="4. mqclass后进先出的内存队列"></a>4. mqclass后进先出的内存队列</h4><p>SCHEDULER_MEMORY_QUEUE = ‘scrapy.squeues.LifoMemoryQueue’从名字上看，是后进先出的内存队列。这个队列是为了使用2中的队列而存在的，不必单独分析。</p>
<h3 id="scheduler源码解释笔记"><a href="#scheduler源码解释笔记" class="headerlink" title="scheduler源码解释笔记"></a>scheduler源码解释笔记</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># scheduler.py</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> join, exists</span><br><span class="line"></span><br><span class="line"><span class="comment"># request_to_dict: 将请求对象转换成dict，如果给定了一个spider，它将尝试找出回调中使用的spider方法的名称，并将其存储为回调。</span></span><br><span class="line"><span class="comment"># request_from_dict：从dict创建请求对象，如果给定了一个spider，它将尝试解析在spider中查找同名方法的回调。</span></span><br><span class="line"><span class="keyword">from</span> scrapy.utils.reqser <span class="keyword">import</span> request_to_dict, request_from_dict</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.misc <span class="keyword">import</span> load_object, create_instance</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.job <span class="keyword">import</span> job_dir</span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(__name__)  <span class="comment"># 获得一个全局的logger对象。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Scheduler</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dupefilter, jobdir=None, dqclass=None, mqclass=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 logunser=False, stats=None, pqclass=None)</span>:</span></span><br><span class="line">        self.df = dupefilter  <span class="comment"># 去重模块    默认利用set在内存去重</span></span><br><span class="line">        self.dqdir = self._dqdir(jobdir)  <span class="comment"># 磁盘队列路径  持久化队列至硬盘</span></span><br><span class="line">        self.pqclass = pqclass  <span class="comment"># 带优先级队列    默认来自queuelib</span></span><br><span class="line">        self.dqclass = dqclass  <span class="comment"># 磁盘队列  持久化队列至硬盘</span></span><br><span class="line">        self.mqclass = mqclass  <span class="comment"># 内存队列  默认来自queuelib</span></span><br><span class="line">        self.logunser = logunser</span><br><span class="line">        self.stats = stats  <span class="comment"># 状态记录  状态记录通用模块</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从crawler的设置获取各个属性， 然后使用load_object 获取对应类。</span></span><br><span class="line">    <span class="comment"># 主要有以下几个名词， 调度优先级队列，调度磁盘队列，调度内存队列。调度debug开启是否，日志非序列化请求，重复类。</span></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_crawler</span><span class="params">(cls, crawler)</span>:</span>  <span class="comment"># 实例化入口    scrapy风格的实例化入口</span></span><br><span class="line">        settings = crawler.settings</span><br><span class="line">        dupefilter_cls = load_object(settings[<span class="string">'DUPEFILTER_CLASS'</span>])</span><br><span class="line">        dupefilter = create_instance(dupefilter_cls, settings, crawler)</span><br><span class="line">        pqclass = load_object(settings[<span class="string">'SCHEDULER_PRIORITY_QUEUE'</span>])  <span class="comment"># 'queuelib.PriorityQueue'</span></span><br><span class="line">        dqclass = load_object(settings[<span class="string">'SCHEDULER_DISK_QUEUE'</span>])  <span class="comment"># 'scrapy.squeues.PickleLifoDiskQueue'</span></span><br><span class="line">        mqclass = load_object(settings[<span class="string">'SCHEDULER_MEMORY_QUEUE'</span>])  <span class="comment"># 'scrapy.squeues.LifoMemoryQueue'</span></span><br><span class="line">        logunser = settings.getbool(<span class="string">'LOG_UNSERIALIZABLE_REQUESTS'</span>, settings.getbool(<span class="string">'SCHEDULER_DEBUG'</span>))</span><br><span class="line">        <span class="keyword">return</span> cls(dupefilter, jobdir=job_dir(settings), logunser=logunser,</span><br><span class="line">                   stats=crawler.stats, pqclass=pqclass, dqclass=dqclass, mqclass=mqclass)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取是否还有请求没处理。 返回true或者false.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">has_pending_requests</span><span class="params">(self)</span>:</span>  <span class="comment"># 检查队列数    指向len</span></span><br><span class="line">        <span class="keyword">return</span> len(self) &gt; <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打开调度器方法： 设置当前的爬虫，设置当前的内存队列，磁盘队列，内存队列初始值为调度优先级队列。</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open</span><span class="params">(self, spider)</span>:</span>  <span class="comment"># 初始化队列    scrapy模块的初始化入口</span></span><br><span class="line">        self.spider = spider</span><br><span class="line">        self.mqs = self.pqclass(self._newmq)</span><br><span class="line">        self.dqs = self._dq() <span class="keyword">if</span> self.dqdir <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> self.df.open()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 关闭调度器方法： 判断dqs， 关闭dqs，打开active.json文件， 把prios信息写进去。关闭df</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(self, reason)</span>:</span>  <span class="comment">#     安全退出接口  scrapy模块的安全入口</span></span><br><span class="line">        <span class="keyword">if</span> self.dqs:</span><br><span class="line">            prios = self.dqs.close()</span><br><span class="line">            <span class="keyword">with</span> open(join(self.dqdir, <span class="string">'active.json'</span>), <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                json.dump(prios, f)</span><br><span class="line">        <span class="keyword">return</span> self.df.close(reason)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># enqueue_request: 请求进队列</span></span><br><span class="line">    <span class="comment"># 如果请求是不过滤的，过滤器df的请求处理过。记录日志， 返回false</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">enqueue_request</span><span class="params">(self, request)</span>:</span>  <span class="comment"># 进队api    调度进队</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> request.dont_filter <span class="keyword">and</span> self.df.request_seen(request):</span><br><span class="line">            self.df.log(request, self.spider)</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        dqok = self._dqpush(request)  <span class="comment"># self._dqpush 这个是磁盘队列加入这个请求</span></span><br><span class="line">        <span class="keyword">if</span> dqok:  <span class="comment"># 如果成功，就给统计信息的disk的对应爬虫加1</span></span><br><span class="line">            self.stats.inc_value(<span class="string">'scheduler/enqueued/disk'</span>, spider=self.spider)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 其他情况的话，就给统计信息的memory的对应爬虫加1</span></span><br><span class="line">            self._mqpush(request)</span><br><span class="line">            self.stats.inc_value(<span class="string">'scheduler/enqueued/memory'</span>, spider=self.spider)</span><br><span class="line">        self.stats.inc_value(<span class="string">'scheduler/enqueued'</span>, spider=self.spider)  <span class="comment"># 总的也需要加1，然后返回true</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># next_request：从队列里取出数据进行处理</span></span><br><span class="line">    <span class="comment"># 获取下一个请求， 先从内存队列mqs里面pop一个，给memory加1，如果内存中为空就从磁盘队列dq里面pop一个。</span></span><br><span class="line">    <span class="comment"># 然后disk加1，如果request不为空， 就给dequed加1</span></span><br><span class="line">    <span class="comment"># 注意这个方法和上个方法， 一个是入，一个是出 的。</span></span><br><span class="line">    <span class="comment"># 统计信息也是， 一个统计到en队列中， 一个统计到de队列去。</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">next_request</span><span class="params">(self)</span>:</span>  <span class="comment"># 出队api    调度出队，t优先从内存队列里取，然后才是磁盘队列</span></span><br><span class="line">        request = self.mqs.pop()</span><br><span class="line">        <span class="keyword">if</span> request:</span><br><span class="line">            self.stats.inc_value(<span class="string">'scheduler/dequeued/memory'</span>, spider=self.spider)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            request = self._dqpop()</span><br><span class="line">            <span class="keyword">if</span> request:</span><br><span class="line">                self.stats.inc_value(<span class="string">'scheduler/dequeued/disk'</span>, spider=self.spider)</span><br><span class="line">        <span class="keyword">if</span> request:</span><br><span class="line">            self.stats.inc_value(<span class="string">'scheduler/dequeued'</span>, spider=self.spider)</span><br><span class="line">        <span class="keyword">return</span> request</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 三目运算， 如果磁盘队列不为空的话， 就是磁盘队列加内存队列的长度， 否则就是内存队列的长度。</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.dqs) + len(self.mqs) <span class="keyword">if</span> self.dqs <span class="keyword">else</span> len(self.mqs)</span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    下面的几个方法，_dqpush，_mqpush，_dqpop，_newmq，_newdq，_dq，_dqdir</span></span><br><span class="line"><span class="string">    从方法名字，看看有push,you pop， new ， 大概可以知道这个是构造，添加，删除操作。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    _newmq: 构造一个内存队列， _newdq: 构造一个磁盘队列。 </span></span><br><span class="line"><span class="string">    具体的列可以看出从setting里面读取过来的。实例化的在这个方面里面的。 返回值就是对应的对象。 </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    _mqpush: 内存队列里面push一个请求， 优先级为请求的负值</span></span><br><span class="line"><span class="string">             </span></span><br><span class="line"><span class="string">    _dqpush: 核心就是请求转化为字典， 然后把dict放到磁盘队列中， 如果有异常，说明是无法序列化请求，构造msg信息。 </span></span><br><span class="line"><span class="string">             记录警告信息。并记录序列化失败个数，最总返回true，有异常那就返回none</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    _dqpop: 从磁盘队列获取pop一个dict，然后将dict转为request。 返回回去。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    _dqdir: 获取dqdir，如果有设置的话， 就会创建一个目录，并返回这个目录</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_dqpush</span><span class="params">(self, request)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.dqs <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            reqd = request_to_dict(request, self.spider)</span><br><span class="line">            self.dqs.push(reqd, -request.priority)</span><br><span class="line">        <span class="keyword">except</span> ValueError <span class="keyword">as</span> e:  <span class="comment"># non serializable request</span></span><br><span class="line">            <span class="keyword">if</span> self.logunser:</span><br><span class="line">                msg = (<span class="string">"Unable to serialize request: %(request)s - reason:"</span></span><br><span class="line">                       <span class="string">" %(reason)s - no more unserializable requests will be"</span></span><br><span class="line">                       <span class="string">" logged (stats being collected)"</span>)</span><br><span class="line">                logger.warning(msg, &#123;<span class="string">'request'</span>: request, <span class="string">'reason'</span>: e&#125;,</span><br><span class="line">                               exc_info=<span class="literal">True</span>, extra=&#123;<span class="string">'spider'</span>: self.spider&#125;)</span><br><span class="line">                self.logunser = <span class="literal">False</span></span><br><span class="line">            self.stats.inc_value(<span class="string">'scheduler/unserializable'</span>,</span><br><span class="line">                                 spider=self.spider)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_mqpush</span><span class="params">(self, request)</span>:</span></span><br><span class="line">        self.mqs.push(request, -request.priority)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_dqpop</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.dqs:</span><br><span class="line">            d = self.dqs.pop()</span><br><span class="line">            <span class="keyword">if</span> d:</span><br><span class="line">                <span class="keyword">return</span> request_from_dict(d, self.spider)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_newmq</span><span class="params">(self, priority)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.mqclass()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_newdq</span><span class="params">(self, priority)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.dqclass(join(self.dqdir, <span class="string">'p%s'</span> % priority))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_dq</span><span class="params">(self)</span>:</span></span><br><span class="line">        activef = join(self.dqdir, <span class="string">'active.json'</span>)</span><br><span class="line">        <span class="keyword">if</span> exists(activef):</span><br><span class="line">            <span class="keyword">with</span> open(activef) <span class="keyword">as</span> f:</span><br><span class="line">                prios = json.load(f)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            prios = ()</span><br><span class="line">        q = self.pqclass(self._newdq, startprios=prios)</span><br><span class="line">        <span class="keyword">if</span> q:</span><br><span class="line">            logger.info(<span class="string">"Resuming crawl (%(queuesize)d requests scheduled)"</span>,</span><br><span class="line">                        &#123;<span class="string">'queuesize'</span>: len(q)&#125;, extra=&#123;<span class="string">'spider'</span>: self.spider&#125;)</span><br><span class="line">        <span class="keyword">return</span> q</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_dqdir</span><span class="params">(self, jobdir)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> jobdir:</span><br><span class="line">            dqdir = join(jobdir, <span class="string">'requests.queue'</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> exists(dqdir):</span><br><span class="line">                os.makedirs(dqdir)</span><br><span class="line">            <span class="keyword">return</span> dqdir</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/06/python/spider/scrapy/20200630_engine/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="崔永华（Andy）">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="崔永华的个人网站">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/06/python/spider/scrapy/20200630_engine/" itemprop="url">
                  scrapy源码1：engine的源码分析
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-06-30T10:35:00+08:00">
                2020-06-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/爬虫/" itemprop="url" rel="index">
                    <span itemprop="name">爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          
            <h4 id="scrapy中engine-py的源码分析如下："><a href="#scrapy中engine-py的源码分析如下：" class="headerlink" title="scrapy中engine.py的源码分析如下："></a>scrapy中engine.py的源码分析如下：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">engine.py提供了2个类：Slot和ExecutionEngine</span></span><br><span class="line"><span class="string">    Slot: 提供了几个方法添加请求，删除请求，关闭自己，触发关闭方法</span></span><br><span class="line"><span class="string">          它使用Twisted的主循环reactor来不断的调度执行Engine的"_next_request"方法，这个方法也是核心循环方法。</span></span><br><span class="line"><span class="string">    ExecutionEngine: 引擎的执行任务</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">爬虫引擎是控制调度器，下载器和爬虫的。</span></span><br><span class="line"><span class="string">This is the Scrapy engine which controls the Scheduler, Downloader and Spiders.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">For more information see docs/topics/architecture.rst</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># Twisted是用Python实现的基于事件驱动的网络引擎框架，这里引用了它，可能用于网络方面</span></span><br><span class="line"><span class="keyword">from</span> twisted.internet <span class="keyword">import</span> defer, task</span><br><span class="line"><span class="keyword">from</span> twisted.python.failure <span class="keyword">import</span> Failure</span><br><span class="line"></span><br><span class="line"><span class="comment"># 接下来导入了一些自己的包</span></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> signals  <span class="comment"># 这些信号记录在 docs/topics/signals.rst. 请不要在没有记录的情况下在此处添加新信号。</span></span><br><span class="line"><span class="string">'''signals源码如下：</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Scrapy signals</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">These signals are documented in docs/topics/signals.rst. Please don't add new</span></span><br><span class="line"><span class="string">signals here without documenting them there.</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">engine_started = object()</span></span><br><span class="line"><span class="string">engine_stopped = object()</span></span><br><span class="line"><span class="string">spider_opened = object()</span></span><br><span class="line"><span class="string">spider_idle = object()  # 爬虫空闲</span></span><br><span class="line"><span class="string">spider_closed = object()</span></span><br><span class="line"><span class="string">spider_error = object()</span></span><br><span class="line"><span class="string">request_scheduled = object()</span></span><br><span class="line"><span class="string">request_dropped = object()</span></span><br><span class="line"><span class="string">request_reached_downloader = object()</span></span><br><span class="line"><span class="string">response_received = object()</span></span><br><span class="line"><span class="string">response_downloaded = object()</span></span><br><span class="line"><span class="string">item_scraped = object()</span></span><br><span class="line"><span class="string">item_dropped = object()</span></span><br><span class="line"><span class="string">item_error = object()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># for backwards compatibility</span></span><br><span class="line"><span class="string">stats_spider_opened = spider_opened</span></span><br><span class="line"><span class="string">stats_spider_closing = spider_closed</span></span><br><span class="line"><span class="string">stats_spider_closed = spider_closed</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">item_passed = item_scraped</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">request_received = request_scheduled</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">from</span> scrapy.core.scraper <span class="keyword">import</span> Scraper  <span class="comment"># scraper:数据抓取器，主要用于从网页中抓取数据的处理。也就是ItemPipeLine的处理。</span></span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DontCloseSpider  <span class="comment"># 从自定义的类里面导入了一个异常类</span></span><br><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> Response, Request  <span class="comment"># 从http里面导入了response,request</span></span><br><span class="line"><span class="keyword">from</span> scrapy.utils.misc <span class="keyword">import</span> load_object  <span class="comment"># 加载给定对象绝对路径的对象，然后返回它;这个方法是传递一个str，返回一个类，方法，变量或者实例</span></span><br><span class="line"><span class="string">'''load_object源码如下：</span></span><br><span class="line"><span class="string">def load_object(path):</span></span><br><span class="line"><span class="string">    """Load an object given its absolute object path, and return it.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    object can be a class, function, variable or an instance.</span></span><br><span class="line"><span class="string">    path ie: 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    try:</span></span><br><span class="line"><span class="string">        dot = path.rindex('.')</span></span><br><span class="line"><span class="string">    except ValueError:</span></span><br><span class="line"><span class="string">        raise ValueError("Error loading object '%s': not a full path" % path)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    module, name = path[:dot], path[dot+1:]</span></span><br><span class="line"><span class="string">    mod = import_module(module)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    try:</span></span><br><span class="line"><span class="string">        obj = getattr(mod, name)</span></span><br><span class="line"><span class="string">    except AttributeError:</span></span><br><span class="line"><span class="string">        raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    return obj</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">from</span> scrapy.utils.reactor <span class="keyword">import</span> CallLaterOnce  <span class="comment"># 调度要在下一个reactor循环中调用的函数，但前提是该函数自上次运行以来尚未被调度</span></span><br><span class="line"><span class="string">'''CallLaterOnce源码如下：</span></span><br><span class="line"><span class="string">class CallLaterOnce(object):</span></span><br><span class="line"><span class="string">    """Schedule a function to be called in the next reactor loop, but only if</span></span><br><span class="line"><span class="string">    it hasn't been already scheduled since the last time it ran.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def __init__(self, func, *a, **kw):</span></span><br><span class="line"><span class="string">        self._func = func</span></span><br><span class="line"><span class="string">        self._a = a</span></span><br><span class="line"><span class="string">        self._kw = kw</span></span><br><span class="line"><span class="string">        self._call = None</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def schedule(self, delay=0):</span></span><br><span class="line"><span class="string">        if self._call is None:</span></span><br><span class="line"><span class="string">            self._call = reactor.callLater(delay, self)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def cancel(self):</span></span><br><span class="line"><span class="string">        if self._call:</span></span><br><span class="line"><span class="string">            self._call.cancel()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def __call__(self):</span></span><br><span class="line"><span class="string">        self._call = None</span></span><br><span class="line"><span class="string">        return self._func(*self._a, **self._kw)</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">from</span> scrapy.utils.log <span class="keyword">import</span> logformatter_adapter, failure_to_exc_info  <span class="comment"># 日志相关</span></span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(__name__)  <span class="comment"># 全局的日志对象</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># slot代表一次nextcall的执行，实际上就是执行一次engine的_next_request。</span></span><br><span class="line"><span class="comment"># slot创建了一个hearbeat，即为一个心跳。通过twisted的task.LoopingCall实现。</span></span><br><span class="line"><span class="comment"># 每隔5s执行一次，尝试处理一个新的request，这属于被动执行。后面还会有主动执行的代码。</span></span><br><span class="line"><span class="comment"># slot可以理解为一个request的生命周期。</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Slot</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, start_requests, close_if_idle, nextcall, scheduler)</span>:</span></span><br><span class="line">        self.closing = <span class="literal">False</span></span><br><span class="line">        self.inprogress = set()  <span class="comment"># requests in progress</span></span><br><span class="line">        self.start_requests = iter(start_requests)</span><br><span class="line">        self.close_if_idle = close_if_idle</span><br><span class="line">        self.nextcall = nextcall</span><br><span class="line">        self.scheduler = scheduler</span><br><span class="line">        self.heartbeat = task.LoopingCall(nextcall.schedule)  <span class="comment"># heartbeat属性在init的时候初始化了，在close的时候调用stop。</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_request</span><span class="params">(self, request)</span>:</span></span><br><span class="line">        self.inprogress.add(request)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">remove_request</span><span class="params">(self, request)</span>:</span></span><br><span class="line">        self.inprogress.remove(request)</span><br><span class="line">        self._maybe_fire_closing()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.closing = defer.Deferred()</span><br><span class="line">        self._maybe_fire_closing()</span><br><span class="line">        <span class="keyword">return</span> self.closing</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_maybe_fire_closing</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.closing <span class="keyword">and</span> <span class="keyword">not</span> self.inprogress:</span><br><span class="line">            <span class="keyword">if</span> self.nextcall:</span><br><span class="line">                self.nextcall.cancel()</span><br><span class="line">                <span class="keyword">if</span> self.heartbeat.running:</span><br><span class="line">                    self.heartbeat.stop()</span><br><span class="line">            self.closing.callback(<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExecutionEngine</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="comment"># 接受crawler爬虫，spider_close_callback 完成初始化工作</span></span><br><span class="line">    <span class="comment"># 接受初始化的几个参数，设置、信号、日志格式、从crawler那里获取到，从设置中加载日志调度类，从设置加载下载类</span></span><br><span class="line">    <span class="comment"># 其中的设置scheduler_cls, downloader_cls, 默认值可以从default_settings.py获取</span></span><br><span class="line">    <span class="comment"># SCHEDULER = 'scrapy.core.scheduler.Scheduler'</span></span><br><span class="line">    <span class="comment"># DOWNLOADER = 'scrapy.core.downloader.Downloader'</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, crawler, spider_closed_callback)</span>:</span></span><br><span class="line">        self.crawler = crawler</span><br><span class="line">        self.settings = crawler.settings</span><br><span class="line">        self.signals = crawler.signals</span><br><span class="line">        self.logformatter = crawler.logformatter</span><br><span class="line">        self.slot = <span class="literal">None</span></span><br><span class="line">        self.spider = <span class="literal">None</span></span><br><span class="line">        self.running = <span class="literal">False</span></span><br><span class="line">        self.paused = <span class="literal">False</span></span><br><span class="line">        self.scheduler_cls = load_object(self.settings[<span class="string">'SCHEDULER'</span>])</span><br><span class="line">        downloader_cls = load_object(self.settings[<span class="string">'DOWNLOADER'</span>])</span><br><span class="line">        self.downloader = downloader_cls(crawler)</span><br><span class="line">        self.scraper = Scraper(crawler)</span><br><span class="line">        self._spider_closed_callback = spider_closed_callback</span><br><span class="line"></span><br><span class="line">    <span class="comment"># start:  启动爬虫引擎，方法上面带了个装饰器 @defer.inlineCallbacks</span></span><br><span class="line">    <span class="comment"># 先去断言引擎的运行状态，记录下开始时间，发送一个引擎启动的信号，设置运行状态为运行，设置_closewait为延迟对象，返回_closewait</span></span><br><span class="line">    <span class="comment"># 或者说：记录启动时间；发送一个"engine_started"消息；设置running标志；创建一个_closewait的Deferred对象并返回。</span></span><br><span class="line"><span class="meta">    @defer.inlineCallbacks</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Start the execution engine"""</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="keyword">not</span> self.running, <span class="string">"Engine already running"</span></span><br><span class="line">        self.start_time = time()</span><br><span class="line">        <span class="keyword">yield</span> self.signals.send_catch_log_deferred(signal=signals.engine_started)</span><br><span class="line">        self.running = <span class="literal">True</span></span><br><span class="line">        <span class="comment"># 这个_closewait会返回给CrawlerProcess，</span></span><br><span class="line">        <span class="comment"># 这个Deferred在引擎结束时才会调用，因此用它来向CrawlerProcess通知一个Crawler已经爬取完毕。</span></span><br><span class="line">        self._closewait = defer.Deferred()</span><br><span class="line">        <span class="keyword">yield</span> self._closewait</span><br><span class="line"></span><br><span class="line">    <span class="comment"># stop : 优雅地停止执行引擎</span></span><br><span class="line">    <span class="comment"># 标记状态running为false, 关闭所有的爬虫, 调用_finish_stopping_engine</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">stop</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Stop the execution engine gracefully"""</span></span><br><span class="line">        <span class="keyword">assert</span> self.running, <span class="string">"Engine not running"</span></span><br><span class="line">        self.running = <span class="literal">False</span></span><br><span class="line">        dfd = self._close_all_spiders()</span><br><span class="line">        <span class="keyword">return</span> dfd.addBoth(<span class="keyword">lambda</span> _: self._finish_stopping_engine())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># close:  优雅的关闭执行引擎</span></span><br><span class="line">    <span class="comment"># 调用stop方法，完成引擎的关闭工作，其他情况下，关闭爬虫和下载器</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Close the execution engine gracefully.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        If it has already been started, stop it. In all cases, close all spiders</span></span><br><span class="line"><span class="string">        and the downloader.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> self.running:</span><br><span class="line">            <span class="comment"># Will also close spiders and downloader</span></span><br><span class="line">            <span class="keyword">return</span> self.stop()</span><br><span class="line">        <span class="keyword">elif</span> self.open_spiders:</span><br><span class="line">            <span class="comment"># Will also close downloader</span></span><br><span class="line">            <span class="keyword">return</span> self._close_all_spiders()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> defer.succeed(self.downloader.close())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># pause:暂停执行引擎</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pause</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Pause the execution engine"""</span></span><br><span class="line">        self.paused = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># unpause:解除引擎的暂停</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">unpause</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Resume the execution engine"""</span></span><br><span class="line">        self.paused = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># _next_request:下次请求</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_next_request</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        slot = self.slot</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> slot:  <span class="comment"># 状态判断</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.paused:  <span class="comment"># 状态判断</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> self._needs_backout(spider):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> self._next_request_from_scheduler(spider):</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 下面if语句，请求不为空，并且爬虫没有处理完毕</span></span><br><span class="line">        <span class="keyword">if</span> slot.start_requests <span class="keyword">and</span> <span class="keyword">not</span> self._needs_backout(spider):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                request = next(slot.start_requests)  <span class="comment"># 调用next方法</span></span><br><span class="line">            <span class="keyword">except</span> StopIteration:</span><br><span class="line">                slot.start_requests = <span class="literal">None</span></span><br><span class="line">            <span class="keyword">except</span> Exception:</span><br><span class="line">                slot.start_requests = <span class="literal">None</span></span><br><span class="line">                logger.error(<span class="string">'Error while obtaining start requests'</span>,</span><br><span class="line">                             exc_info=<span class="literal">True</span>, extra=&#123;<span class="string">'spider'</span>: spider&#125;)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.crawl(request, spider)  <span class="comment"># 否则去调用crawl方法。</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果爬虫是空闲的，并且爬虫空闲则关闭 是true的话，调用_spider_idle方法。</span></span><br><span class="line">        <span class="keyword">if</span> self.spider_is_idle(spider) <span class="keyword">and</span> slot.close_if_idle:</span><br><span class="line">            self._spider_idle(spider)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># _needs_backout: 返回一个布尔值</span></span><br><span class="line">    <span class="comment"># 如果引擎关闭则返回true, 或者slot关闭，或者下载器那里返回了true, 或者爬虫那里返回true,</span></span><br><span class="line">    <span class="comment"># 后面的那2个needs_backout需要具体到downloader, scrper类里面去看。</span></span><br><span class="line">    <span class="comment"># 我们可以对这个方法的理解为没有接下来的工作了就返回true</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_needs_backout</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        slot = self.slot</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">not</span> self.running \</span><br><span class="line">            <span class="keyword">or</span> slot.closing \</span><br><span class="line">            <span class="keyword">or</span> self.downloader.needs_backout() \</span><br><span class="line">            <span class="keyword">or</span> self.scraper.slot.needs_backout()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># _next_request_from_scheduler: 从调度器获取下一个请求， 判断request,下载请求</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_next_request_from_scheduler</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        slot = self.slot</span><br><span class="line">        request = slot.scheduler.next_request()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> request:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        d = self._download(request, spider)</span><br><span class="line">        d.addBoth(self._handle_downloader_output, request, spider)</span><br><span class="line">        d.addErrback(<span class="keyword">lambda</span> f: logger.info(<span class="string">'Error while handling downloader output'</span>,</span><br><span class="line">                                           exc_info=failure_to_exc_info(f),</span><br><span class="line">                                           extra=&#123;<span class="string">'spider'</span>: spider&#125;))</span><br><span class="line">        d.addBoth(<span class="keyword">lambda</span> _: slot.remove_request(request))</span><br><span class="line">        d.addErrback(<span class="keyword">lambda</span> f: logger.info(<span class="string">'Error while removing request from slot'</span>,</span><br><span class="line">                                           exc_info=failure_to_exc_info(f),</span><br><span class="line">                                           extra=&#123;<span class="string">'spider'</span>: spider&#125;))</span><br><span class="line">        d.addBoth(<span class="keyword">lambda</span> _: slot.nextcall.schedule())</span><br><span class="line">        d.addErrback(<span class="keyword">lambda</span> f: logger.info(<span class="string">'Error while scheduling new request'</span>,</span><br><span class="line">                                           exc_info=failure_to_exc_info(f),</span><br><span class="line">                                           extra=&#123;<span class="string">'spider'</span>: spider&#125;))</span><br><span class="line">        <span class="keyword">return</span> d</span><br><span class="line"></span><br><span class="line">    <span class="comment"># _handle_downloader_output : 处理下载的输出</span></span><br><span class="line">    <span class="comment"># 断言response为request,response,failure ,如果是request则调用crawl方法，如果是响应enqueue_scrape处理。</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_handle_downloader_output</span><span class="params">(self, response, request, spider)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> isinstance(response, (Request, Response, Failure)), response</span><br><span class="line">        <span class="comment"># downloader middleware can return requests (for example, redirects)</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(response, Request):</span><br><span class="line">            self.crawl(response, spider)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="comment"># response is a Response or Failure</span></span><br><span class="line">        d = self.scraper.enqueue_scrape(response, request, spider)</span><br><span class="line">        d.addErrback(<span class="keyword">lambda</span> f: logger.error(<span class="string">'Error while enqueuing downloader output'</span>,</span><br><span class="line">                                            exc_info=failure_to_exc_info(f),</span><br><span class="line">                                            extra=&#123;<span class="string">'spider'</span>: spider&#125;))</span><br><span class="line">        <span class="keyword">return</span> d</span><br><span class="line"></span><br><span class="line">    <span class="comment"># spider_is_idle: 判定爬虫是否是空闲的</span></span><br><span class="line">    <span class="comment"># 判定slot空闲，判定下载空闲，判定请求为空，判定调度器没有要处理的请求</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">spider_is_idle</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.scraper.slot.is_idle():</span><br><span class="line">            <span class="comment"># scraper is not idle</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downloader.active:</span><br><span class="line">            <span class="comment"># downloader has pending requests</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.slot.start_requests <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># not all start requests are handled</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.slot.scheduler.has_pending_requests():</span><br><span class="line">            <span class="comment"># scheduler has pending requests</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># open_spiders: 打开爬虫</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spiders</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> [self.spider] <span class="keyword">if</span> self.spider <span class="keyword">else</span> []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># has_capacity: 判断是否有能力处理更多的爬虫引擎</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">has_capacity</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Does the engine have capacity to handle more spiders"""</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">not</span> bool(self.slot)  <span class="comment"># 初始化时规定了self.slot = None</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># crawl : 爬取，先断言爬虫是打开的，执行调度，执行回调的调度</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">crawl</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> spider <span class="keyword">in</span> self.open_spiders, \</span><br><span class="line">            <span class="string">"Spider %r not opened when crawling: %s"</span> % (spider.name, request)</span><br><span class="line">        self.schedule(request, spider)</span><br><span class="line">        self.slot.nextcall.schedule()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># schedule : 调度，发出请求调度事件，如果enqueue_request ,  则触发请求丢弃事件。</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">schedule</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        self.signals.send_catch_log(signal=signals.request_scheduled,</span><br><span class="line">                request=request, spider=spider)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.slot.scheduler.enqueue_request(request):</span><br><span class="line">            self.signals.send_catch_log(signal=signals.request_dropped,</span><br><span class="line">                                        request=request, spider=spider)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># download : 下载, 调用内部方法_download</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        d = self._download(request, spider)</span><br><span class="line">        d.addBoth(self._downloaded, self.slot, request, spider)</span><br><span class="line">        <span class="keyword">return</span> d</span><br><span class="line"></span><br><span class="line">    <span class="comment"># _download : 内部方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_downloaded</span><span class="params">(self, response, slot, request, spider)</span>:</span></span><br><span class="line">        slot.remove_request(request)</span><br><span class="line">        <span class="keyword">return</span> self.download(response, spider) \</span><br><span class="line">                <span class="keyword">if</span> isinstance(response, Request) <span class="keyword">else</span> response</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 添加请求， 定义一个成功的方法，一个完成的方法，从下载器里面提取对象, getaway添加成功回调，添加完成。</span></span><br><span class="line">    <span class="comment"># addCallbacks,addBoth 这2个方法用的挺多的</span></span><br><span class="line">    <span class="comment"># addcallbacks 接受一个成功的回调方法， 一个失败的回调方法，</span></span><br><span class="line">    <span class="comment"># addBoth函数向callback与errback链中添加了相同的回调函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_download</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        slot = self.slot</span><br><span class="line">        slot.add_request(request)</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">_on_success</span><span class="params">(response)</span>:</span></span><br><span class="line">            <span class="keyword">assert</span> isinstance(response, (Response, Request))</span><br><span class="line">            <span class="keyword">if</span> isinstance(response, Response):</span><br><span class="line">                response.request = request  <span class="comment"># tie request to response received</span></span><br><span class="line">                logkws = self.logformatter.crawled(request, response, spider)</span><br><span class="line">                logger.log(*logformatter_adapter(logkws), extra=&#123;<span class="string">'spider'</span>: spider&#125;)</span><br><span class="line">                self.signals.send_catch_log(signal=signals.response_received, \</span><br><span class="line">                    response=response, request=request, spider=spider)</span><br><span class="line">            <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">_on_complete</span><span class="params">(_)</span>:</span></span><br><span class="line">            slot.nextcall.schedule()</span><br><span class="line">            <span class="keyword">return</span> _</span><br><span class="line"></span><br><span class="line">        dwld = self.downloader.fetch(request, spider)</span><br><span class="line">        dwld.addCallbacks(_on_success)</span><br><span class="line">        dwld.addBoth(_on_complete)</span><br><span class="line">        <span class="keyword">return</span> dwld</span><br><span class="line"></span><br><span class="line">    <span class="comment"># open_spider：打开爬虫</span></span><br><span class="line">    <span class="comment"># 先断言容量，记录info日志，获取nextcall;</span></span><br><span class="line">    <span class="comment"># 通过crawler构造scheduler调度器，构造slot对象，调度器打开爬虫，爬虫打开，出发爬虫打开事件，启动心跳信息。</span></span><br><span class="line"><span class="meta">    @defer.inlineCallbacks</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider, start_requests=<span class="params">()</span>, close_if_idle=True)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> self.has_capacity(), <span class="string">"No free spider slot when opening %r"</span> % \</span><br><span class="line">            spider.name</span><br><span class="line">        logger.info(<span class="string">"Spider opened"</span>, extra=&#123;<span class="string">'spider'</span>: spider&#125;)</span><br><span class="line">        nextcall = CallLaterOnce(self._next_request, spider)</span><br><span class="line">        scheduler = self.scheduler_cls.from_crawler(self.crawler)</span><br><span class="line">        start_requests = <span class="keyword">yield</span> self.scraper.spidermw.process_start_requests(start_requests, spider)</span><br><span class="line">        slot = Slot(start_requests, close_if_idle, nextcall, scheduler)</span><br><span class="line">        self.slot = slot</span><br><span class="line">        self.spider = spider</span><br><span class="line">        <span class="keyword">yield</span> scheduler.open(spider)</span><br><span class="line">        <span class="keyword">yield</span> self.scraper.open_spider(spider)</span><br><span class="line">        self.crawler.stats.open_spider(spider)</span><br><span class="line">        <span class="keyword">yield</span> self.signals.send_catch_log_deferred(signals.spider_opened, spider=spider)</span><br><span class="line">        slot.nextcall.schedule()</span><br><span class="line">        slot.heartbeat.start(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># _spider_idle: 爬虫空闲， 判定空闲， 如果空闲的话，关闭爬虫</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_spider_idle</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        <span class="string">"""Called when a spider gets idle. This function is called when there</span></span><br><span class="line"><span class="string">        are no remaining pages to download or schedule. It can be called</span></span><br><span class="line"><span class="string">        multiple times. If some extension raises a DontCloseSpider exception</span></span><br><span class="line"><span class="string">        (in the spider_idle signal handler) the spider is not closed until the</span></span><br><span class="line"><span class="string">        next loop and this function is guaranteed to be called (at least) once</span></span><br><span class="line"><span class="string">        again for this spider.</span></span><br><span class="line"><span class="string">        翻译：当爬虫空闲时调用。在没有剩余的页面可供下载或调度时，调用此函数。可以称之为</span></span><br><span class="line"><span class="string">        多次。如果某个扩展引发DontCloseSpider异常（在spider_idle信号处理器中）直到</span></span><br><span class="line"><span class="string">        下一个循环这个爬虫才关闭，这个函数保证爬虫被调用（至少）一次。</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        res = self.signals.send_catch_log(signal=signals.spider_idle, \</span><br><span class="line">            spider=spider, dont_log=DontCloseSpider)</span><br><span class="line">        <span class="keyword">if</span> any(isinstance(x, Failure) <span class="keyword">and</span> isinstance(x.value, DontCloseSpider) \</span><br><span class="line">                <span class="keyword">for</span> _, x <span class="keyword">in</span> res):</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.spider_is_idle(spider):</span><br><span class="line">            self.close_spider(spider, reason=<span class="string">'finished'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># close_spider : 关闭爬虫，绑定各种错误回调。</span></span><br><span class="line">    <span class="comment"># 关闭（取消）spider并清除所有未完成的请求</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider, reason=<span class="string">'cancelled'</span>)</span>:</span></span><br><span class="line">        <span class="string">"""Close (cancel) spider and clear all its outstanding requests"""</span></span><br><span class="line"></span><br><span class="line">        slot = self.slot</span><br><span class="line">        <span class="keyword">if</span> slot.closing:</span><br><span class="line">            <span class="keyword">return</span> slot.closing</span><br><span class="line">        logger.info(<span class="string">"Closing spider (%(reason)s)"</span>,</span><br><span class="line">                    &#123;<span class="string">'reason'</span>: reason&#125;,</span><br><span class="line">                    extra=&#123;<span class="string">'spider'</span>: spider&#125;)</span><br><span class="line"></span><br><span class="line">        dfd = slot.close()</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">log_failure</span><span class="params">(msg)</span>:</span></span><br><span class="line">            <span class="function"><span class="keyword">def</span> <span class="title">errback</span><span class="params">(failure)</span>:</span></span><br><span class="line">                logger.error(</span><br><span class="line">                    msg,</span><br><span class="line">                    exc_info=failure_to_exc_info(failure),</span><br><span class="line">                    extra=&#123;<span class="string">'spider'</span>: spider&#125;</span><br><span class="line">                )</span><br><span class="line">            <span class="keyword">return</span> errback</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: self.downloader.close())</span><br><span class="line">        dfd.addErrback(log_failure(<span class="string">'Downloader close failure'</span>))</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: self.scraper.close_spider(spider))</span><br><span class="line">        dfd.addErrback(log_failure(<span class="string">'Scraper close failure'</span>))</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: slot.scheduler.close(reason))</span><br><span class="line">        dfd.addErrback(log_failure(<span class="string">'Scheduler close failure'</span>))</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: self.signals.send_catch_log_deferred(</span><br><span class="line">            signal=signals.spider_closed, spider=spider, reason=reason))</span><br><span class="line">        dfd.addErrback(log_failure(<span class="string">'Error while sending spider_close signal'</span>))</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: self.crawler.stats.close_spider(spider, reason=reason))</span><br><span class="line">        dfd.addErrback(log_failure(<span class="string">'Stats close failure'</span>))</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: logger.info(<span class="string">"Spider closed (%(reason)s)"</span>,</span><br><span class="line">                                          &#123;<span class="string">'reason'</span>: reason&#125;,</span><br><span class="line">                                          extra=&#123;<span class="string">'spider'</span>: spider&#125;))</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: setattr(self, <span class="string">'slot'</span>, <span class="literal">None</span>))</span><br><span class="line">        dfd.addErrback(log_failure(<span class="string">'Error while unassigning slot'</span>))</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: setattr(self, <span class="string">'spider'</span>, <span class="literal">None</span>))</span><br><span class="line">        dfd.addErrback(log_failure(<span class="string">'Error while unassigning spider'</span>))</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: self._spider_closed_callback(spider))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dfd</span><br><span class="line"></span><br><span class="line">    <span class="comment"># _close_all_spiders :关闭所有的爬虫，遍历爬虫，执行关闭操作</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_close_all_spiders</span><span class="params">(self)</span>:</span></span><br><span class="line">        dfds = [self.close_spider(s, reason=<span class="string">'shutdown'</span>) <span class="keyword">for</span> s <span class="keyword">in</span> self.open_spiders]</span><br><span class="line">        dlist = defer.DeferredList(dfds)</span><br><span class="line">        <span class="keyword">return</span> dlist</span><br><span class="line"></span><br><span class="line">    <span class="comment"># _finish_stopping_engine : 结束引擎，触发引擎关闭操作。</span></span><br><span class="line"><span class="meta">    @defer.inlineCallbacks</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_finish_stopping_engine</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">yield</span> self.signals.send_catch_log_deferred(signal=signals.engine_stopped)</span><br><span class="line">        self._closewait.callback(<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<h5 id="实际源码中engine-py"><a href="#实际源码中engine-py" class="headerlink" title="实际源码中engine.py"></a>实际源码中engine.py</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">This is the Scrapy engine which controls the Scheduler, Downloader and Spiders. </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">For more information see docs/topics/architecture.rst</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> twisted.internet <span class="keyword">import</span> defer, task</span><br><span class="line"><span class="keyword">from</span> twisted.python.failure <span class="keyword">import</span> Failure</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> signals</span><br><span class="line"><span class="keyword">from</span> scrapy.core.scraper <span class="keyword">import</span> Scraper</span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DontCloseSpider</span><br><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> Response, Request</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.misc <span class="keyword">import</span> load_object</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.reactor <span class="keyword">import</span> CallLaterOnce</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.log <span class="keyword">import</span> logformatter_adapter, failure_to_exc_info</span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Slot</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, start_requests, close_if_idle, nextcall, scheduler)</span>:</span></span><br><span class="line">        self.closing = <span class="literal">False</span></span><br><span class="line">        self.inprogress = set() <span class="comment"># requests in progress</span></span><br><span class="line">        self.start_requests = iter(start_requests)</span><br><span class="line">        self.close_if_idle = close_if_idle</span><br><span class="line">        self.nextcall = nextcall</span><br><span class="line">        self.scheduler = scheduler</span><br><span class="line">        self.heartbeat = task.LoopingCall(nextcall.schedule)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_request</span><span class="params">(self, request)</span>:</span></span><br><span class="line">        self.inprogress.add(request)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">remove_request</span><span class="params">(self, request)</span>:</span></span><br><span class="line">        self.inprogress.remove(request)</span><br><span class="line">        self._maybe_fire_closing()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.closing = defer.Deferred()</span><br><span class="line">        self._maybe_fire_closing()</span><br><span class="line">        <span class="keyword">return</span> self.closing</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_maybe_fire_closing</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.closing <span class="keyword">and</span> <span class="keyword">not</span> self.inprogress:</span><br><span class="line">            <span class="keyword">if</span> self.nextcall:</span><br><span class="line">                self.nextcall.cancel()</span><br><span class="line">                <span class="keyword">if</span> self.heartbeat.running:</span><br><span class="line">                    self.heartbeat.stop()</span><br><span class="line">            self.closing.callback(<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExecutionEngine</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, crawler, spider_closed_callback)</span>:</span></span><br><span class="line">        self.crawler = crawler</span><br><span class="line">        self.settings = crawler.settings</span><br><span class="line">        self.signals = crawler.signals</span><br><span class="line">        self.logformatter = crawler.logformatter</span><br><span class="line">        self.slot = <span class="literal">None</span></span><br><span class="line">        self.spider = <span class="literal">None</span></span><br><span class="line">        self.running = <span class="literal">False</span></span><br><span class="line">        self.paused = <span class="literal">False</span></span><br><span class="line">        self.scheduler_cls = load_object(self.settings[<span class="string">'SCHEDULER'</span>])</span><br><span class="line">        downloader_cls = load_object(self.settings[<span class="string">'DOWNLOADER'</span>])</span><br><span class="line">        self.downloader = downloader_cls(crawler)</span><br><span class="line">        self.scraper = Scraper(crawler)</span><br><span class="line">        self._spider_closed_callback = spider_closed_callback</span><br><span class="line"></span><br><span class="line"><span class="meta">    @defer.inlineCallbacks</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Start the execution engine"""</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="keyword">not</span> self.running, <span class="string">"Engine already running"</span></span><br><span class="line">        self.start_time = time()</span><br><span class="line">        <span class="keyword">yield</span> self.signals.send_catch_log_deferred(signal=signals.engine_started)</span><br><span class="line">        self.running = <span class="literal">True</span></span><br><span class="line">        self._closewait = defer.Deferred()</span><br><span class="line">        <span class="keyword">yield</span> self._closewait</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">stop</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Stop the execution engine gracefully"""</span></span><br><span class="line">        <span class="keyword">assert</span> self.running, <span class="string">"Engine not running"</span></span><br><span class="line">        self.running = <span class="literal">False</span></span><br><span class="line">        dfd = self._close_all_spiders()</span><br><span class="line">        <span class="keyword">return</span> dfd.addBoth(<span class="keyword">lambda</span> _: self._finish_stopping_engine())</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Close the execution engine gracefully.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        If it has already been started, stop it. In all cases, close all spiders</span></span><br><span class="line"><span class="string">        and the downloader.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> self.running:</span><br><span class="line">            <span class="comment"># Will also close spiders and downloader</span></span><br><span class="line">            <span class="keyword">return</span> self.stop()</span><br><span class="line">        <span class="keyword">elif</span> self.open_spiders:</span><br><span class="line">            <span class="comment"># Will also close downloader</span></span><br><span class="line">            <span class="keyword">return</span> self._close_all_spiders()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> defer.succeed(self.downloader.close())</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pause</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Pause the execution engine"""</span></span><br><span class="line">        self.paused = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">unpause</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Resume the execution engine"""</span></span><br><span class="line">        self.paused = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_next_request</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        slot = self.slot</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> slot:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.paused:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> self._needs_backout(spider):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> self._next_request_from_scheduler(spider):</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> slot.start_requests <span class="keyword">and</span> <span class="keyword">not</span> self._needs_backout(spider):</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                request = next(slot.start_requests)</span><br><span class="line">            <span class="keyword">except</span> StopIteration:</span><br><span class="line">                slot.start_requests = <span class="literal">None</span></span><br><span class="line">            <span class="keyword">except</span> Exception:</span><br><span class="line">                slot.start_requests = <span class="literal">None</span></span><br><span class="line">                logger.error(<span class="string">'Error while obtaining start requests'</span>,</span><br><span class="line">                             exc_info=<span class="literal">True</span>, extra=&#123;<span class="string">'spider'</span>: spider&#125;)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.crawl(request, spider)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.spider_is_idle(spider) <span class="keyword">and</span> slot.close_if_idle:</span><br><span class="line">            self._spider_idle(spider)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_needs_backout</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        slot = self.slot</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">not</span> self.running \</span><br><span class="line">            <span class="keyword">or</span> slot.closing \</span><br><span class="line">            <span class="keyword">or</span> self.downloader.needs_backout() \</span><br><span class="line">            <span class="keyword">or</span> self.scraper.slot.needs_backout()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_next_request_from_scheduler</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        slot = self.slot</span><br><span class="line">        request = slot.scheduler.next_request()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> request:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        d = self._download(request, spider)</span><br><span class="line">        d.addBoth(self._handle_downloader_output, request, spider)</span><br><span class="line">        d.addErrback(<span class="keyword">lambda</span> f: logger.info(<span class="string">'Error while handling downloader output'</span>,</span><br><span class="line">                                           exc_info=failure_to_exc_info(f),</span><br><span class="line">                                           extra=&#123;<span class="string">'spider'</span>: spider&#125;))</span><br><span class="line">        d.addBoth(<span class="keyword">lambda</span> _: slot.remove_request(request))</span><br><span class="line">        d.addErrback(<span class="keyword">lambda</span> f: logger.info(<span class="string">'Error while removing request from slot'</span>,</span><br><span class="line">                                           exc_info=failure_to_exc_info(f),</span><br><span class="line">                                           extra=&#123;<span class="string">'spider'</span>: spider&#125;))</span><br><span class="line">        d.addBoth(<span class="keyword">lambda</span> _: slot.nextcall.schedule())</span><br><span class="line">        d.addErrback(<span class="keyword">lambda</span> f: logger.info(<span class="string">'Error while scheduling new request'</span>,</span><br><span class="line">                                           exc_info=failure_to_exc_info(f),</span><br><span class="line">                                           extra=&#123;<span class="string">'spider'</span>: spider&#125;))</span><br><span class="line">        <span class="keyword">return</span> d</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_handle_downloader_output</span><span class="params">(self, response, request, spider)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> isinstance(response, (Request, Response, Failure)), response</span><br><span class="line">        <span class="comment"># downloader middleware can return requests (for example, redirects)</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(response, Request):</span><br><span class="line">            self.crawl(response, spider)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="comment"># response is a Response or Failure</span></span><br><span class="line">        d = self.scraper.enqueue_scrape(response, request, spider)</span><br><span class="line">        d.addErrback(<span class="keyword">lambda</span> f: logger.error(<span class="string">'Error while enqueuing downloader output'</span>,</span><br><span class="line">                                            exc_info=failure_to_exc_info(f),</span><br><span class="line">                                            extra=&#123;<span class="string">'spider'</span>: spider&#125;))</span><br><span class="line">        <span class="keyword">return</span> d</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">spider_is_idle</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.scraper.slot.is_idle():</span><br><span class="line">            <span class="comment"># scraper is not idle</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downloader.active:</span><br><span class="line">            <span class="comment"># downloader has pending requests</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.slot.start_requests <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># not all start requests are handled</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.slot.scheduler.has_pending_requests():</span><br><span class="line">            <span class="comment"># scheduler has pending requests</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spiders</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> [self.spider] <span class="keyword">if</span> self.spider <span class="keyword">else</span> []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">has_capacity</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Does the engine have capacity to handle more spiders"""</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">not</span> bool(self.slot)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">crawl</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> spider <span class="keyword">in</span> self.open_spiders, \</span><br><span class="line">            <span class="string">"Spider %r not opened when crawling: %s"</span> % (spider.name, request)</span><br><span class="line">        self.schedule(request, spider)</span><br><span class="line">        self.slot.nextcall.schedule()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">schedule</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        self.signals.send_catch_log(signal=signals.request_scheduled,</span><br><span class="line">                request=request, spider=spider)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.slot.scheduler.enqueue_request(request):</span><br><span class="line">            self.signals.send_catch_log(signal=signals.request_dropped,</span><br><span class="line">                                        request=request, spider=spider)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">download</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        d = self._download(request, spider)</span><br><span class="line">        d.addBoth(self._downloaded, self.slot, request, spider)</span><br><span class="line">        <span class="keyword">return</span> d</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_downloaded</span><span class="params">(self, response, slot, request, spider)</span>:</span></span><br><span class="line">        slot.remove_request(request)</span><br><span class="line">        <span class="keyword">return</span> self.download(response, spider) \</span><br><span class="line">                <span class="keyword">if</span> isinstance(response, Request) <span class="keyword">else</span> response</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_download</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        slot = self.slot</span><br><span class="line">        slot.add_request(request)</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">_on_success</span><span class="params">(response)</span>:</span></span><br><span class="line">            <span class="keyword">assert</span> isinstance(response, (Response, Request))</span><br><span class="line">            <span class="keyword">if</span> isinstance(response, Response):</span><br><span class="line">                response.request = request <span class="comment"># tie request to response received</span></span><br><span class="line">                logkws = self.logformatter.crawled(request, response, spider)</span><br><span class="line">                logger.log(*logformatter_adapter(logkws), extra=&#123;<span class="string">'spider'</span>: spider&#125;)</span><br><span class="line">                self.signals.send_catch_log(signal=signals.response_received, \</span><br><span class="line">                    response=response, request=request, spider=spider)</span><br><span class="line">            <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">_on_complete</span><span class="params">(_)</span>:</span></span><br><span class="line">            slot.nextcall.schedule()</span><br><span class="line">            <span class="keyword">return</span> _</span><br><span class="line"></span><br><span class="line">        dwld = self.downloader.fetch(request, spider)</span><br><span class="line">        dwld.addCallbacks(_on_success)</span><br><span class="line">        dwld.addBoth(_on_complete)</span><br><span class="line">        <span class="keyword">return</span> dwld</span><br><span class="line"></span><br><span class="line"><span class="meta">    @defer.inlineCallbacks</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider, start_requests=<span class="params">()</span>, close_if_idle=True)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> self.has_capacity(), <span class="string">"No free spider slot when opening %r"</span> % \</span><br><span class="line">            spider.name</span><br><span class="line">        logger.info(<span class="string">"Spider opened"</span>, extra=&#123;<span class="string">'spider'</span>: spider&#125;)</span><br><span class="line">        nextcall = CallLaterOnce(self._next_request, spider)</span><br><span class="line">        scheduler = self.scheduler_cls.from_crawler(self.crawler)</span><br><span class="line">        start_requests = <span class="keyword">yield</span> self.scraper.spidermw.process_start_requests(start_requests, spider)</span><br><span class="line">        slot = Slot(start_requests, close_if_idle, nextcall, scheduler)</span><br><span class="line">        self.slot = slot</span><br><span class="line">        self.spider = spider</span><br><span class="line">        <span class="keyword">yield</span> scheduler.open(spider)</span><br><span class="line">        <span class="keyword">yield</span> self.scraper.open_spider(spider)</span><br><span class="line">        self.crawler.stats.open_spider(spider)</span><br><span class="line">        <span class="keyword">yield</span> self.signals.send_catch_log_deferred(signals.spider_opened, spider=spider)</span><br><span class="line">        slot.nextcall.schedule()</span><br><span class="line">        slot.heartbeat.start(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_spider_idle</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        <span class="string">"""Called when a spider gets idle. This function is called when there</span></span><br><span class="line"><span class="string">        are no remaining pages to download or schedule. It can be called</span></span><br><span class="line"><span class="string">        multiple times. If some extension raises a DontCloseSpider exception</span></span><br><span class="line"><span class="string">        (in the spider_idle signal handler) the spider is not closed until the</span></span><br><span class="line"><span class="string">        next loop and this function is guaranteed to be called (at least) once</span></span><br><span class="line"><span class="string">        again for this spider.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        res = self.signals.send_catch_log(signal=signals.spider_idle, \</span><br><span class="line">            spider=spider, dont_log=DontCloseSpider)</span><br><span class="line">        <span class="keyword">if</span> any(isinstance(x, Failure) <span class="keyword">and</span> isinstance(x.value, DontCloseSpider) \</span><br><span class="line">                <span class="keyword">for</span> _, x <span class="keyword">in</span> res):</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.spider_is_idle(spider):</span><br><span class="line">            self.close_spider(spider, reason=<span class="string">'finished'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider, reason=<span class="string">'cancelled'</span>)</span>:</span></span><br><span class="line">        <span class="string">"""Close (cancel) spider and clear all its outstanding requests"""</span></span><br><span class="line"></span><br><span class="line">        slot = self.slot</span><br><span class="line">        <span class="keyword">if</span> slot.closing:</span><br><span class="line">            <span class="keyword">return</span> slot.closing</span><br><span class="line">        logger.info(<span class="string">"Closing spider (%(reason)s)"</span>,</span><br><span class="line">                    &#123;<span class="string">'reason'</span>: reason&#125;,</span><br><span class="line">                    extra=&#123;<span class="string">'spider'</span>: spider&#125;)</span><br><span class="line"></span><br><span class="line">        dfd = slot.close()</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">log_failure</span><span class="params">(msg)</span>:</span></span><br><span class="line">            <span class="function"><span class="keyword">def</span> <span class="title">errback</span><span class="params">(failure)</span>:</span></span><br><span class="line">                logger.error(</span><br><span class="line">                    msg,</span><br><span class="line">                    exc_info=failure_to_exc_info(failure),</span><br><span class="line">                    extra=&#123;<span class="string">'spider'</span>: spider&#125;</span><br><span class="line">                )</span><br><span class="line">            <span class="keyword">return</span> errback</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: self.downloader.close())</span><br><span class="line">        dfd.addErrback(log_failure(<span class="string">'Downloader close failure'</span>))</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: self.scraper.close_spider(spider))</span><br><span class="line">        dfd.addErrback(log_failure(<span class="string">'Scraper close failure'</span>))</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: slot.scheduler.close(reason))</span><br><span class="line">        dfd.addErrback(log_failure(<span class="string">'Scheduler close failure'</span>))</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: self.signals.send_catch_log_deferred(</span><br><span class="line">            signal=signals.spider_closed, spider=spider, reason=reason))</span><br><span class="line">        dfd.addErrback(log_failure(<span class="string">'Error while sending spider_close signal'</span>))</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: self.crawler.stats.close_spider(spider, reason=reason))</span><br><span class="line">        dfd.addErrback(log_failure(<span class="string">'Stats close failure'</span>))</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: logger.info(<span class="string">"Spider closed (%(reason)s)"</span>,</span><br><span class="line">                                          &#123;<span class="string">'reason'</span>: reason&#125;,</span><br><span class="line">                                          extra=&#123;<span class="string">'spider'</span>: spider&#125;))</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: setattr(self, <span class="string">'slot'</span>, <span class="literal">None</span>))</span><br><span class="line">        dfd.addErrback(log_failure(<span class="string">'Error while unassigning slot'</span>))</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: setattr(self, <span class="string">'spider'</span>, <span class="literal">None</span>))</span><br><span class="line">        dfd.addErrback(log_failure(<span class="string">'Error while unassigning spider'</span>))</span><br><span class="line"></span><br><span class="line">        dfd.addBoth(<span class="keyword">lambda</span> _: self._spider_closed_callback(spider))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dfd</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_close_all_spiders</span><span class="params">(self)</span>:</span></span><br><span class="line">        dfds = [self.close_spider(s, reason=<span class="string">'shutdown'</span>) <span class="keyword">for</span> s <span class="keyword">in</span> self.open_spiders]</span><br><span class="line">        dlist = defer.DeferredList(dfds)</span><br><span class="line">        <span class="keyword">return</span> dlist</span><br><span class="line"></span><br><span class="line"><span class="meta">    @defer.inlineCallbacks</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_finish_stopping_engine</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">yield</span> self.signals.send_catch_log_deferred(signal=signals.engine_stopped)</span><br><span class="line">        self._closewait.callback(<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/06/database/my-post2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="崔永华（Andy）">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="崔永华的个人网站">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/06/database/my-post2/" itemprop="url">
                  python...
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-06-23T15:24:20+08:00">
                2020-06-23
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/编程语言/" itemprop="url" rel="index">
                    <span itemprop="name">编程语言</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          <h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>近年来大数据BigData、人工智能AI、物联网Iot等行业发展迅猛，很多人都想要从事大数据技术开发工作，但是，请问要<code>怎么做</code>，<code>路线是什么？从哪里开始学？学哪些？</code>这是一个大问题。对于我自己来说，最近也在学一些大数据开发相关的技术，所以之前整理了一份<code>《大数据技术学习路线》</code>，希望对你有所帮助。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2020/06/database/my-post2/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/my-post6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="崔永华（Andy）">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="崔永华的个人网站">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2020/04/my-post6/" itemprop="url">
                  PostgreSQL的内部结构
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-04-01T15:30:00+08:00">
                2020-04-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数据库/" itemprop="url" rel="index">
                    <span itemprop="name">数据库</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数据库/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          <blockquote>
<p>聊两个问题，它们看似和推荐系统没有必然关系，但实际上，在你构建自己的推荐系统的时候，不可避免地会遇到这两个问题。</p>
</blockquote>
<h2 id="一-去重是刚需–0099"><a href="#一-去重是刚需–0099" class="headerlink" title="一. 去重是刚需–0099"></a>一. 去重是刚需–0099</h2><p>在推荐系统中，有一个刚需就是去重，那么说在哪些地方有去重的需求呢？<br>主要是在两个地方：一个是内容源去重，另一个是不重复给用户推荐。</p>
          <!--noindex-->
          <div class="post-button text-center">
            <a class="btn" href="/2020/04/my-post6/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/database/PostgreSql/20190927_mysql更改数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="崔永华（Andy）">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="崔永华的个人网站">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/09/database/PostgreSql/20190927_mysql更改数据/" itemprop="url">
                  MySQL中增加，更新或删除 数据库中原数据的内容
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-27T15:24:20+08:00">
                2019-09-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数据库/" itemprop="url" rel="index">
                    <span itemprop="name">数据库</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数据库/PostgreSQL/" itemprop="url" rel="index">
                    <span itemprop="name">PostgreSQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          
            <h5 id="1-向原数据增加内容"><a href="#1-向原数据增加内容" class="headerlink" title="1. 向原数据增加内容"></a>1. 向原数据增加内容</h5><p>原表为：<br><img src="https://img-blog.csdnimg.cn/20190927194903520.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2N1aV95b25naHVh,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>执行sql语句：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在name字段下数据的前面加上 ‘我的’ 字段</span></span><br><span class="line"><span class="keyword">update</span> person_info <span class="keyword">set</span> <span class="keyword">name</span> = <span class="keyword">concat</span>(<span class="string">'我的'</span>, <span class="keyword">name</span>)</span><br></pre></td></tr></table></figure>
<p>增加之后的结果为：<br><img src="https://img-blog.csdnimg.cn/20190927200408938.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2N1aV95b25naHVh,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h5 id="2-修改原数据的内容"><a href="#2-修改原数据的内容" class="headerlink" title="2. 修改原数据的内容"></a>2. 修改原数据的内容</h5><p>语法：replace(object,search,replace) ， 把object中出现search的全部替换为replace</p>
<p>执行的sql:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在name字段下， 把 ‘我’ 替换成 ‘你们’</span></span><br><span class="line"><span class="keyword">update</span> person_info <span class="keyword">set</span> <span class="keyword">name</span> = <span class="keyword">replace</span>(<span class="keyword">name</span>, <span class="string">'我'</span>, <span class="string">'你们'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20190927200935992.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2N1aV95b25naHVh,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h5 id="3-删除原数据的内容"><a href="#3-删除原数据的内容" class="headerlink" title="3. 删除原数据的内容"></a>3. 删除原数据的内容</h5><p>执行的sql如下</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在name字段下， 把 ‘我们的’ 替换成 ‘’</span></span><br><span class="line"><span class="keyword">update</span> person_info <span class="keyword">set</span> <span class="keyword">name</span> = <span class="keyword">replace</span>(<span class="keyword">name</span>, <span class="string">'你们的'</span>, <span class="string">''</span>)</span><br></pre></td></tr></table></figure>
<p>执行的结果如下图：<br><img src="https://img-blog.csdnimg.cn/20190927201239730.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2N1aV95b25naHVh,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>注：如果想增加，更新或删除数据的部分内容，可指定要操作的字段<br>比如：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">update</span> person_info <span class="keyword">set</span> <span class="keyword">name</span> = <span class="keyword">replace</span>(<span class="keyword">name</span>, <span class="string">'china'</span>, <span class="string">'chinamoney'</span>) <span class="keyword">where</span> <span class="keyword">id</span> <span class="keyword">in</span> (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/database/PostgreSql/20190921_每5分钟mysql的插入量/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="崔永华（Andy）">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="崔永华的个人网站">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/09/database/PostgreSql/20190921_每5分钟mysql的插入量/" itemprop="url">
                  统计每5分钟，MySQL数据库中数据的插入量
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-21T15:24:20+08:00">
                2019-09-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数据库/" itemprop="url" rel="index">
                    <span itemprop="name">数据库</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数据库/PostgreSQL/" itemprop="url" rel="index">
                    <span itemprop="name">PostgreSQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          
            <p>统计每5分钟，MySQL数据库中数据的插入量，id，start_time，end_time都在表sk_job_execution中。 </p>
<p><img src="https://img-blog.csdnimg.cn/20190921110153538.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2N1aV95b25naHVh,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">time</span>, <span class="keyword">COUNT</span>( * ) <span class="keyword">AS</span> <span class="keyword">num</span> </span><br><span class="line"><span class="keyword">FROM</span></span><br><span class="line">	(</span><br><span class="line">	<span class="keyword">SELECT</span> <span class="keyword">id</span>,</span><br><span class="line">		<span class="keyword">DATE_FORMAT</span>(</span><br><span class="line">			<span class="keyword">concat</span>( <span class="built_in">date</span>(start_time ), <span class="string">' '</span>, <span class="keyword">HOUR</span> ( start_time ), <span class="string">':'</span>, <span class="keyword">floor</span>( <span class="keyword">MINUTE</span> ( start_time ) / <span class="number">5</span> ) * <span class="number">5</span> ),</span><br><span class="line">			<span class="string">'%Y-%m-%d %H:%i'</span> </span><br><span class="line">		) <span class="keyword">AS</span> <span class="built_in">time</span> </span><br><span class="line">	<span class="keyword">FROM</span> sk_job_execution</span><br><span class="line">	<span class="keyword">where</span> start_time <span class="keyword">BETWEEN</span> <span class="string">'2019-09-20 00:00:00'</span> <span class="keyword">and</span> <span class="string">'2019-09-21 10:00:00'</span>  </span><br><span class="line">	) a </span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">DATE_FORMAT</span>( <span class="built_in">time</span>, <span class="string">'%Y-%m-%d %H:%i'</span> ) </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="built_in">time</span>;</span><br></pre></td></tr></table></figure>
<p>执行结果如下图所示：<br><img src="https://img-blog.csdnimg.cn/20190921110302492.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2N1aV95b25naHVh,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/database/PostgreSql/20190909_查看pg内存/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="崔永华（Andy）">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="崔永华的个人网站">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2019/09/database/PostgreSql/20190909_查看pg内存/" itemprop="url">
                  查询PostgreSQL占多大内存
                </a>
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-09T15:24:20+08:00">
                2019-09-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数据库/" itemprop="url" rel="index">
                    <span itemprop="name">数据库</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/数据库/PostgreSQL/" itemprop="url" rel="index">
                    <span itemprop="name">PostgreSQL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        
          
            <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> pg_size_pretty(pg_relation_size(<span class="string">'cuiyonghua.top_iqiyi_info'</span>));</span><br><span class="line"><span class="keyword">select</span> pg_size_pretty(pg_relation_size(<span class="string">'cuiyonghua.top_mgtv_info'</span>));</span><br><span class="line"><span class="keyword">select</span> pg_size_pretty(pg_relation_size(<span class="string">'cuiyonghua.top_tencent_info'</span>));</span><br><span class="line"><span class="keyword">select</span> pg_size_pretty(pg_relation_size(<span class="string">'cuiyonghua.top_zhihu_info'</span>));</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20190909143029367.png" alt="在这里插入图片描述"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/uploads/avatar.png" alt="崔永华（Andy）">
          <p class="site-author-name" itemprop="name">崔永华（Andy）</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">69</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">32</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">36</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/cuiyonghua6" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://blog.csdn.net/cui_yonghua" target="_blank" title="CSDN">
                  
                    <i class="fa fa-fw fa-bandcamp"></i>
                  
                  CSDN
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/cuiyonghua" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  知乎
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://weibo.com/cuiyonghua" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">崔永华（Andy）</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  

  
    <span class="site-pv">
      本站总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  





  





  






  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>





  

  

  

  

  

</body>
</html>
